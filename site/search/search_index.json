{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Graph Neural Network Cancer Drug Response (gnnCDR) A major goal in precision oncology is to match a patient and tumor to the optimal therapeutic treatment. Research towards these goals include identifying drug combinations or repurposing drugs used in other domains to address limitations in oncology treatment durability, drug resistance and patient toxicity. We seek to accelerate and improve drug development by developing algorithms that improve how we identify therapeutic drug combinations based on \u2018omic features and improve predictions of drug response. Project Summary Ineffective or limited precision oncology treatments are a cause of patient mortality. We seek to address this challenge by improving pre-clinical drug repurposing and drug combination discovery. We highlight the methodological challenge of training drug response models using single-drug data that will generalize well to multi-drug perturbations. We operate on the premise that protein-protein interactions mediate cellular drug response and hypothesize that incorporating this prior knowledge in a deep learning framework is liable to overcome limitations in drug response modeling and enable novel approaches to drug prioritization. To do this we will predict drug perturbed mRNA expression from intrinsic cancer features using graph neural networks that operate on literature curated protein-protein and drug-target interactions. In preliminary research, we have developed a synthetic data generator, which we have used to show promise and feasibility of our approach. We will develop and evaluate our methods using synthetic data before applying it to cancer cell line drug-perturbed mRNA expression datasets to prioritize drug combinations. Therapeutic candidates will be empirically evaluated in Dr. Gordon Mills\u2019 and Dr. Jeffrey Tyner\u2019s labs. Successful implementation of our methods will enable tractable and robust drug prioritization based on nuanced therapeutic goals such as user-defined cell type selective response. Installation ...","title":"Home"},{"location":"#graph-neural-network-cancer-drug-response-gnncdr","text":"A major goal in precision oncology is to match a patient and tumor to the optimal therapeutic treatment. Research towards these goals include identifying drug combinations or repurposing drugs used in other domains to address limitations in oncology treatment durability, drug resistance and patient toxicity. We seek to accelerate and improve drug development by developing algorithms that improve how we identify therapeutic drug combinations based on \u2018omic features and improve predictions of drug response.","title":"Graph Neural Network Cancer Drug Response (gnnCDR)"},{"location":"#project-summary","text":"Ineffective or limited precision oncology treatments are a cause of patient mortality. We seek to address this challenge by improving pre-clinical drug repurposing and drug combination discovery. We highlight the methodological challenge of training drug response models using single-drug data that will generalize well to multi-drug perturbations. We operate on the premise that protein-protein interactions mediate cellular drug response and hypothesize that incorporating this prior knowledge in a deep learning framework is liable to overcome limitations in drug response modeling and enable novel approaches to drug prioritization. To do this we will predict drug perturbed mRNA expression from intrinsic cancer features using graph neural networks that operate on literature curated protein-protein and drug-target interactions. In preliminary research, we have developed a synthetic data generator, which we have used to show promise and feasibility of our approach. We will develop and evaluate our methods using synthetic data before applying it to cancer cell line drug-perturbed mRNA expression datasets to prioritize drug combinations. Therapeutic candidates will be empirically evaluated in Dr. Gordon Mills\u2019 and Dr. Jeffrey Tyner\u2019s labs. Successful implementation of our methods will enable tractable and robust drug prioritization based on nuanced therapeutic goals such as user-defined cell type selective response.","title":"Project Summary"},{"location":"#installation","text":"...","title":"Installation"},{"location":"data/","text":"Data Overview Synthetic Data GeneNetWeaver (GNW) GNW-L1000 ... Real Data LICNS L1000 DepMap Reactome FI CMAP drug data","title":"Data Overview"},{"location":"data/#data-overview","text":"","title":"Data Overview"},{"location":"data/#synthetic-data","text":"","title":"Synthetic Data"},{"location":"data/#genenetweaver-gnw","text":"","title":"GeneNetWeaver (GNW)"},{"location":"data/#gnw-l1000","text":"...","title":"GNW-L1000"},{"location":"data/#real-data","text":"","title":"Real Data"},{"location":"data/#licns-l1000","text":"","title":"LICNS L1000"},{"location":"data/#depmap","text":"","title":"DepMap"},{"location":"data/#reactome-fi","text":"","title":"Reactome FI"},{"location":"data/#cmap-drug-data","text":"","title":"CMAP drug data"},{"location":"motivation/","text":"Drug Resistance in Cancer Precision oncology operates on the concept that cancers can effectively be killed by targeting specific cancer genetics or states. This has seen remarkable success in a variety of cancers; however, this field has been stymied by the evolved or adaptive drug resistance . One of the major models of targeted therapies of drug resistance can be viewed in the figure below [1]. Drug resistance is estimated to be responsible for up to 90% of the deaths in cancer patients taking chemotherapy or targeted therapies [2]. A common model of drug resistance is that of evolved resistance, in which the therapy acts as a selective pressure - e.g., killing of sensitive cancer clones, but leaving behind a cadre of resistance clones that grow into a resistant tumor. Image source [1]. Drug combinations to combat drug resistance Drug combinations have been proposed as method of preventing drug resistance and resensitizing multi-drug resistance. This is rationalized along several dimensions. First, by targeting multiple driver genes, it may be possible to reduce residual disease as a greater number of cancer clones are plausibly sensitive. Additionally, by using more than one drug it may be possible to resensitize a drug-resistant tumor, leading to renewed sensitivity and better patient outcome. Last, drug synergy occurs when two drugs in combination have an improved response than either of the drugs individually - this behavior can improve patient outcome and/or reduce side effects and toxicity. References De Conti G, Dias MH, Bernards R. Fighting Drug Resistance through the Targeting of Drug-Tolerant Persister Cells. Cancers. 2021; 13(5):1118. https://doi.org/10.3390/cancers13051118 Bukowski K, Kciuk M, Kontek R. Mechanisms of Multidrug Resistance in Cancer Chemotherapy. Int J Mol Sci. 2020;21(9):3233. Published 2020 May 2. doi:10.3390/ijms21093233","title":"Motivation"},{"location":"motivation/#drug-resistance-in-cancer","text":"Precision oncology operates on the concept that cancers can effectively be killed by targeting specific cancer genetics or states. This has seen remarkable success in a variety of cancers; however, this field has been stymied by the evolved or adaptive drug resistance . One of the major models of targeted therapies of drug resistance can be viewed in the figure below [1]. Drug resistance is estimated to be responsible for up to 90% of the deaths in cancer patients taking chemotherapy or targeted therapies [2]. A common model of drug resistance is that of evolved resistance, in which the therapy acts as a selective pressure - e.g., killing of sensitive cancer clones, but leaving behind a cadre of resistance clones that grow into a resistant tumor. Image source [1].","title":"Drug Resistance in Cancer"},{"location":"motivation/#drug-combinations-to-combat-drug-resistance","text":"Drug combinations have been proposed as method of preventing drug resistance and resensitizing multi-drug resistance. This is rationalized along several dimensions. First, by targeting multiple driver genes, it may be possible to reduce residual disease as a greater number of cancer clones are plausibly sensitive. Additionally, by using more than one drug it may be possible to resensitize a drug-resistant tumor, leading to renewed sensitivity and better patient outcome. Last, drug synergy occurs when two drugs in combination have an improved response than either of the drugs individually - this behavior can improve patient outcome and/or reduce side effects and toxicity.","title":"Drug combinations to combat drug resistance"},{"location":"motivation/#references","text":"De Conti G, Dias MH, Bernards R. Fighting Drug Resistance through the Targeting of Drug-Tolerant Persister Cells. Cancers. 2021; 13(5):1118. https://doi.org/10.3390/cancers13051118 Bukowski K, Kciuk M, Kontek R. Mechanisms of Multidrug Resistance in Cancer Chemotherapy. Int J Mol Sci. 2020;21(9):3233. Published 2020 May 2. doi:10.3390/ijms21093233","title":"References"},{"location":"problem_overview/","text":"Gene Regulatory Networks (GRN) We can define transcriptional machinery by using graphical models called gene regulatory networks (GRN). GRNs are directed graphs that link either proteins -> proteins or proteins -> Transcription Factors (TF) or TFs -> Proteins . Edge types can be categorized by the type of interaction, for instance: physical binding between two proteins expression activation between a TF and a protein expression inhibition between a TF and a protein Image source . Drug-Target Interactions (DTI) The pharmacological model of ligand binding applies to most small molecules used in targeted therapies. In this model we conceptualize a given drug binding to one or more proteins with specificity and varying levels of affinity. The drug presence changes protein structure in a way that modifies the protein's behavior or interactions with other cellular components. Drug or genetic perturbation assays There are several assays available that measure the gene expression (mRNA or protein) of a cell line before and after exposure to a given perturbagen. These assays have been performed extensively to provide large datasets characterizing the transcriptional and proteomic response to millions of perturbagens (both chemical or genetic). These datasets can, in general be though of as having 3 main components: unperturbed gene expression (no drug present) perturbed gene expression, measured at time ( \\(t\\) ) time ( \\(t\\) ) after introduction of a pertubagen that the gene expression was measured. Incorporating GRNs, DTI and perturbation assays in a single framework Gene Regulatory Networks and Drug Target Interactions can be encoded in a heterogenous graph, with nodes consisting of proteins and pertubagens, a simple version of this is visualized in the figure below. Edges may characterize PPI interactions (expression regulation, binding, etc.) or characterize relationships between drugs and proteins (drug targets). Considering the dimensionality and complexity of the human interactome, this network in practice would become quite massive: 20,000+ proteins nodes 1000-100000 perturbagen nodes However, in this model of pertubation - we can further divide individual pertubations into subgraphs that contain only descendents of a single or set of pertubations. See the figure below for an example of individual pertubation subgraphs: Predicting perturbed expression using Graph Neural Networks (GNN) Using these perturbation subgraphs as a framework, we can formulate the prediction of perturbed expression as a node regression task. Node features could be overlaid to characterize the specifics of a given experiment - for instance: the concentration of a drug a given cell lines genomic or transcriptional properties node properties: (drug) chemical SMILES or chemical properies (protein) protein amino acid sequence Global features of the graph might include: tissue type auxillary experimental conditions (DMSO conc., growth hormones, protocol) total drug concentration Edge Features might include: flux or confidence of a PPI edge interaction type binding affinity information of a drug-protein edge The dependant variable (y) that our model will predict is the perturbed expression of a given protein node. To effectively learn a function that maps our heterogenous graph and node features to node prediction we suggest using a Graph Neural Network (GNN). Cell Context Considerations It is well understood that GRNs vary significantly from tissue to tissue and between cell types. This highlights a need to either: A) `Learn context specific edges` B) `Provide context specfic input graphs` C) Learn GNN functions that can mediate context specific behavior based on contextual node features. Additionally, individual proteins may also have contextually specific features - such as the production and degredation rates of a protein. One standing question is, what features might be predictive of such protein-specific features? Or do we need to learn these features directly from the perturbation data?","title":"Problem Overview"},{"location":"problem_overview/#gene-regulatory-networks-grn","text":"We can define transcriptional machinery by using graphical models called gene regulatory networks (GRN). GRNs are directed graphs that link either proteins -> proteins or proteins -> Transcription Factors (TF) or TFs -> Proteins . Edge types can be categorized by the type of interaction, for instance: physical binding between two proteins expression activation between a TF and a protein expression inhibition between a TF and a protein Image source .","title":"Gene Regulatory Networks (GRN)"},{"location":"problem_overview/#drug-target-interactions-dti","text":"The pharmacological model of ligand binding applies to most small molecules used in targeted therapies. In this model we conceptualize a given drug binding to one or more proteins with specificity and varying levels of affinity. The drug presence changes protein structure in a way that modifies the protein's behavior or interactions with other cellular components.","title":"Drug-Target Interactions (DTI)"},{"location":"problem_overview/#drug-or-genetic-perturbation-assays","text":"There are several assays available that measure the gene expression (mRNA or protein) of a cell line before and after exposure to a given perturbagen. These assays have been performed extensively to provide large datasets characterizing the transcriptional and proteomic response to millions of perturbagens (both chemical or genetic). These datasets can, in general be though of as having 3 main components: unperturbed gene expression (no drug present) perturbed gene expression, measured at time ( \\(t\\) ) time ( \\(t\\) ) after introduction of a pertubagen that the gene expression was measured.","title":"Drug or genetic perturbation assays"},{"location":"problem_overview/#incorporating-grns-dti-and-perturbation-assays-in-a-single-framework","text":"Gene Regulatory Networks and Drug Target Interactions can be encoded in a heterogenous graph, with nodes consisting of proteins and pertubagens, a simple version of this is visualized in the figure below. Edges may characterize PPI interactions (expression regulation, binding, etc.) or characterize relationships between drugs and proteins (drug targets). Considering the dimensionality and complexity of the human interactome, this network in practice would become quite massive: 20,000+ proteins nodes 1000-100000 perturbagen nodes However, in this model of pertubation - we can further divide individual pertubations into subgraphs that contain only descendents of a single or set of pertubations. See the figure below for an example of individual pertubation subgraphs:","title":"Incorporating GRNs, DTI and perturbation assays in a single framework"},{"location":"problem_overview/#predicting-perturbed-expression-using-graph-neural-networks-gnn","text":"Using these perturbation subgraphs as a framework, we can formulate the prediction of perturbed expression as a node regression task. Node features could be overlaid to characterize the specifics of a given experiment - for instance: the concentration of a drug a given cell lines genomic or transcriptional properties node properties: (drug) chemical SMILES or chemical properies (protein) protein amino acid sequence Global features of the graph might include: tissue type auxillary experimental conditions (DMSO conc., growth hormones, protocol) total drug concentration Edge Features might include: flux or confidence of a PPI edge interaction type binding affinity information of a drug-protein edge The dependant variable (y) that our model will predict is the perturbed expression of a given protein node. To effectively learn a function that maps our heterogenous graph and node features to node prediction we suggest using a Graph Neural Network (GNN).","title":"Predicting perturbed expression using Graph Neural Networks (GNN)"},{"location":"problem_overview/#cell-context-considerations","text":"It is well understood that GRNs vary significantly from tissue to tissue and between cell types. This highlights a need to either: A) `Learn context specific edges` B) `Provide context specfic input graphs` C) Learn GNN functions that can mediate context specific behavior based on contextual node features. Additionally, individual proteins may also have contextually specific features - such as the production and degredation rates of a protein. One standing question is, what features might be predictive of such protein-specific features? Or do we need to learn these features directly from the perturbation data?","title":"Cell Context Considerations"},{"location":"01_synth_data/data_obj/","text":"The Synthetic gnnCDR data object Now that we've generated synthetic data, we need to organize it in a format conducive to graph neural networks . We will use pytorch_geometric to build our deep learning models, and use the HeteroData object to structure the training data. We will format our synthetic data as a heterogenous graph with 6 node types: protein agonist inhibitor KO (knockout) KD (knockdown) OE (overexpression) and 7 edge types: (agonist, targets, protein) (inhibitor, targets, protein) (KO, targets, protein) (KD, targets, protein) (OE, targets, protein) (protein, activates, protein) (protein, inhibits, protein) The genetic nodes do not have any node attributes and only target a single protein. The chemical perturbations have concentration node attributes ( conc ) and can target multiple protein nodes. Protein-protein edges can be of two types: \"activate\" and \"inhibit\". This is illustrated in figure 1 below. Figure 1 : Graphic of our HeteroData object. For programatic simplicity, we have opted to include all perturbation nodes in each observation graph, and specify active perturbations with non-zero node attributes. For chemical perturbations (agonist, inhibitor) this node attribute represents concentration. For genetic perturbations (KO, KD, OE), we use a arbitrary non-zero value of 1 to specify an active perturbation. HeteroSynthDataset Object We extend the pytorch_geometric Dataset object and create a HeteroSynthDataset which functions to parse the synthetic hdf5 file and produce individual observations of the form described above. The perturbation indexing remains the same across all observations. A dataset object can be initialized by: dataset = SynthHeteroDataset('../../data/synthetic_data.h5', indices=None, zscore=False, x_noise=None, y_noise=None, x_sparsity=None, y_sparsity=None, ppi_false=None, dti_false=None, ppi_missing=None, dti_missing=None, seed=None) Passing an array of integers to indices (indexed by the synthetic_data.h5 ) will specfy what data will be included in the dataset. This can be used to specify train/test splits or filter observations. Here are two examples of a returned data object. perturbation: agonist_2 HeteroData( line=[1], context=[1, 10], time=[1], baseline=[1, 100], y=[1, 100], pert_all=[1, 88], pert_name=[1], conc=[1], pert_type=[1], protein={ x=[100, 1], y=[100, 1], num_nodes=100 }, KO={ x=[26, 1], num_nodes=26 }, KD={ x=[26, 1], num_nodes=26 }, OE={ x=[26, 1], }, ... (inhibitor, targets, protein)={ edge_index=[2, 18], edge_attr=[18, 1] } )","title":"The Synthetic gnnCDR Data Object"},{"location":"01_synth_data/data_obj/#the-synthetic-gnncdr-data-object","text":"Now that we've generated synthetic data, we need to organize it in a format conducive to graph neural networks . We will use pytorch_geometric to build our deep learning models, and use the HeteroData object to structure the training data. We will format our synthetic data as a heterogenous graph with 6 node types: protein agonist inhibitor KO (knockout) KD (knockdown) OE (overexpression) and 7 edge types: (agonist, targets, protein) (inhibitor, targets, protein) (KO, targets, protein) (KD, targets, protein) (OE, targets, protein) (protein, activates, protein) (protein, inhibits, protein) The genetic nodes do not have any node attributes and only target a single protein. The chemical perturbations have concentration node attributes ( conc ) and can target multiple protein nodes. Protein-protein edges can be of two types: \"activate\" and \"inhibit\". This is illustrated in figure 1 below. Figure 1 : Graphic of our HeteroData object. For programatic simplicity, we have opted to include all perturbation nodes in each observation graph, and specify active perturbations with non-zero node attributes. For chemical perturbations (agonist, inhibitor) this node attribute represents concentration. For genetic perturbations (KO, KD, OE), we use a arbitrary non-zero value of 1 to specify an active perturbation.","title":"The Synthetic gnnCDR data object"},{"location":"01_synth_data/data_obj/#heterosynthdataset-object","text":"We extend the pytorch_geometric Dataset object and create a HeteroSynthDataset which functions to parse the synthetic hdf5 file and produce individual observations of the form described above. The perturbation indexing remains the same across all observations. A dataset object can be initialized by: dataset = SynthHeteroDataset('../../data/synthetic_data.h5', indices=None, zscore=False, x_noise=None, y_noise=None, x_sparsity=None, y_sparsity=None, ppi_false=None, dti_false=None, ppi_missing=None, dti_missing=None, seed=None) Passing an array of integers to indices (indexed by the synthetic_data.h5 ) will specfy what data will be included in the dataset. This can be used to specify train/test splits or filter observations. Here are two examples of a returned data object. perturbation: agonist_2 HeteroData( line=[1], context=[1, 10], time=[1], baseline=[1, 100], y=[1, 100], pert_all=[1, 88], pert_name=[1], conc=[1], pert_type=[1], protein={ x=[100, 1], y=[100, 1], num_nodes=100 }, KO={ x=[26, 1], num_nodes=26 }, KD={ x=[26, 1], num_nodes=26 }, OE={ x=[26, 1], }, ... (inhibitor, targets, protein)={ edge_index=[2, 18], edge_attr=[18, 1] } )","title":"HeteroSynthDataset Object"},{"location":"01_synth_data/data_split/","text":"Creating the Train-Test-Validation datasets We will create three datasets, train : ALL genetic perturbations + a proportion of single agents test : a proportion of single agent data validation : This will be combination data only. Single-agent Datasets The Train and Test splits will only have single-agent perturbations. Since our model attempts to learn drug-specific parameters (binding affinity information) we can not exculde a drug entirely for the training dataset. Instead, we will group observations by cell-line + drug pairs and separate them into either train or test datasets. This allows us to train drug-specific parameters while still testing on unseen cell-line responses. This procedure is illustrated in figure 1. Combination-agent Dataset The validation set will include only chemical combination-agent data. Performance on this data subset is the ultimate goal of our project. Example MySplitter = gnn_cdr.utils.DataSplitter('../data/synthetic_data.h5', train_test_ratio=0.8, include_genetic_perts=True) splits = MySplitter.get_idxs() print('# train obs:', splits['train'].shape[0]) print('# test obs:', splits['test'].shape[0]) print('# val observations:', splits['val'].shape[0]) Output: # train obs: 13530 # test obs: 550 # val observations: 123750","title":"Creating Train/Test/Val Datasets"},{"location":"01_synth_data/data_split/#creating-the-train-test-validation-datasets","text":"We will create three datasets, train : ALL genetic perturbations + a proportion of single agents test : a proportion of single agent data validation : This will be combination data only.","title":"Creating the Train-Test-Validation datasets"},{"location":"01_synth_data/data_split/#single-agent-datasets","text":"The Train and Test splits will only have single-agent perturbations. Since our model attempts to learn drug-specific parameters (binding affinity information) we can not exculde a drug entirely for the training dataset. Instead, we will group observations by cell-line + drug pairs and separate them into either train or test datasets. This allows us to train drug-specific parameters while still testing on unseen cell-line responses. This procedure is illustrated in figure 1.","title":"Single-agent Datasets"},{"location":"01_synth_data/data_split/#combination-agent-dataset","text":"The validation set will include only chemical combination-agent data. Performance on this data subset is the ultimate goal of our project.","title":"Combination-agent Dataset"},{"location":"01_synth_data/data_split/#example","text":"MySplitter = gnn_cdr.utils.DataSplitter('../data/synthetic_data.h5', train_test_ratio=0.8, include_genetic_perts=True) splits = MySplitter.get_idxs() print('# train obs:', splits['train'].shape[0]) print('# test obs:', splits['test'].shape[0]) print('# val observations:', splits['val'].shape[0]) Output: # train obs: 13530 # test obs: 550 # val observations: 123750","title":"Example"},{"location":"01_synth_data/generation/","text":"Synthetic Data Model We use the GeneNetWeaver package to simulate synthetic data Figure 1 : GeneNetWeaver graphic from the original paper. We focus on package elements illustrated by section B. source . To simulate data for initial model training and evaluation, we have extended the GeneNetWeaver package (1) , which uses ordinary differential equations (ODEs) built from a gene regulatory network (GRN) to simulate bulk mRNA gene expression under a variety of conditions. GNW outputs include: cell line steady state gene expression in the absence of any perturbation and gene expression time series after the introduction of genetic or chemical perturbation. GNW uses ODEs of the form: \\[ \\frac{dx_i}{dt} = m_i f_i(y) - \\lambda_i^{RNA} x_i \\] \\[ \\frac{dy_i}{dt} = r_i x_i - \\lambda_i^{PROT} y_i \\] Where \\(x_i\\) is RNA gene expression. \\(y_i\\) is protein abundance. \\(m_i\\) and \\(r_i\\) are production rates. \\(f_i(y)\\) is a function of transcription factor activation and \\(\\lambda\\) represents respective degradation rates. Subscript \\(i\\) represents the respective gene index. Building upon the GNW method, we simulate knockout\u2019s (KO) by setting to zero, knockdown\u2019s (KD) by setting to half its original value and over-expression (OE) by setting to twice it\u2019s original value. Chemical perturbations are simulated by randomly sampling a set of gene targets and respective dissociation constants and modifying the target gene values according to the equation: \\[ m_i^{perturbed} = m_i \\pm \\frac{m_i}{1+\\frac{k_d}{c}} \\] Where \\(k_d\\) represents dissociation constant and c is concentration in micro-molars. We simulate multi-drug combinations by modifying the union of drug targets. Drug target collisions are handled by either... Same drug types (2-agent combination): $$ m_i^{perturberd} = m \\pm m_i * \\frac{c_1}{c_1 + k_{d,1}(1 + \\frac{c_2}{k_{d,2}})} $$ Different drug types (2-agent combination): $$ m_i^{perturberd} = \\frac{m_i^{agonist} + m_i^{inhibitor}}{2} $$ We note the accepted scientific premise of pharmacological binding is that a drug binds to protein and stabilizes an active or inactive conformation. This premise suggests that a logical extension would be the modification of protein abundance or transcription factor activation; However, in practice we find that our approach to drug simulation creates reasonable outputs and captures many aspects of true drug perturbation behavior. Different cell contexts (such as cell type, patient, disease, etc.) have varying GRNs, which result in unique expression steady states and perturbation response. To emulate this behavior, we simulate each cellular context by creating a similar - but distinct \u2013 GRN prior to GNW simulation. Cellular context GRNs are created by randomly removing a subset of edges from the original parent GRN. This modified GRN becomes input to the GNW simulation. This work provides a tool for simulating the LINCS L1000 datatypes. Importantly, the data produced by this method is mediated by an underlying GRN, which makes graph-based methods uniquely suited to modeling the data. Generating Synthetic Data For a detailed walk-through of synthetic data pipeline, see gnnCDR/examples/gnw_tutorial.ipynb Settings Modify the local settings.txt file, which must be stored in the .../gnnCDR/gnn_cdr/gnw/gnw/settings.txt The relevant parameters to modify include... # ideal-waddle Relevant parameters # Default max duration time in time-series experiments (must be consistent with numTimePoints_ and dt_) maxtTimeSeries = 500 # Time step for the time series (numTimePoints_ = (int) Math.round(maxtTimeSeries/dt) + 1) dt = 50 # Number of cell line models to create (n-1 single gene KO models + original) n_cell_lines = 10 # probability of edge removal when making cell line models prob_remove = 0.1 # Graph name to use as base PPI network # InSilicoSize100-Ecoli1.tsv graph_name = InSilicoSize100-Ecoli1.tsv # Number of agonist drugs to create num_agonists = 5 # Number of inhibitor drugs to create num_inhibitors = 5 # minimum concentration to use for drug simulations, intended to be in units log10(uM) min_log_conc = -5 # max conc \"\"\" max_log_conc = 1 # number of concentrations to simulate, spread evenly from min_log_conc to max_log_conc on a log scale num_dose_pts = 5 # The expectation (mean) of the number of targets each drug has. Targets are assigned probabalistically so some will have more and some will have fewer. expected_targs = 2 # minimum dissociation constant (kd) value to assign to drug targets (units of log(uM)) min_kd = -3 # max binding affinity max_kd = 0 Usage To simulate data and produce the desired hdf5 file, first update the settings.txt file found in gnn_cdr/gnw/gnw/ to reflect your desired parameters. Next, navigate to the scripts directory and run: (gnnCDR) $ python create_synthetic_data.py --gnw_cwd ../gnn_cdr/gnw/gnw/ --out ../synthetic_data.h5 For command line options, use --help . Output The resulting hdf5 file will have the following general structure: ################################################## Printing HDF5 output structure. ################################################## baseline <HDF5 dataset \"cell_lines\": shape (25,), type \"|S12\"> <HDF5 dataset \"expr\": shape (25, 100), type \"<f8\"> graphs PPI <HDF5 dataset \"edge_attr\": shape (125, 2), type \"<f8\"> <HDF5 dataset \"edge_index\": shape (2, 125), type \"<i4\"> <HDF5 dataset \"edge_labels\": shape (2,), type \"|O\"> PTI <HDF5 dataset \"binding_affinity\": shape (120,), type \"<f8\"> <HDF5 dataset \"edge_attr\": shape (120, 5), type \"<i8\"> <HDF5 dataset \"edge_index\": shape (2, 120), type \"<i8\"> <HDF5 dataset \"edge_labels\": shape (5,), type \"|O\"> labels <HDF5 dataset \"drug_names\": shape (88,), type \"|S11\"> <HDF5 dataset \"gene_names\": shape (100,), type \"|S4\"> meta cell_models <HDF5 dataset \"cell_line_0\": shape (9, 2), type \"|S3\"> <HDF5 dataset \"cell_line_1\": shape (10, 2), type \"|S3\"> ... <HDF5 dataset \"cell_line_8\": shape (7, 2), type \"|S3\"> <HDF5 dataset \"cell_line_9\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_models_info\": shape (1,), type \"|S54\"> <HDF5 dataset \"creation_date\": shape (), type \"|O\"> edgelist <HDF5 dataset \"annot\": shape (125,), type \"|S1\"> <HDF5 dataset \"from\": shape (125,), type \"|S3\"> <HDF5 dataset \"to\": shape (125,), type \"|S4\"> <HDF5 dataset \"settings\": shape (), type \"|O\"> perts <HDF5 dataset \"cell_line\": shape (344850,), type \"|S12\"> <HDF5 dataset \"conc_um\": shape (344850,), type \"|S46\"> <HDF5 dataset \"expr\": shape (344850, 100), type \"<f8\"> <HDF5 dataset \"pert_kd\": shape (344850,), type \"|S260\"> <HDF5 dataset \"pert_name\": shape (344850,), type \"|S24\"> <HDF5 dataset \"pert_targ\": shape (344850,), type \"|S58\"> <HDF5 dataset \"pert_type\": shape (344850,), type \"|S20\"> <HDF5 dataset \"time\": shape (344850,), type \"<f8\"> Output PCA (left) Colored by cell context (middle) colored by perturbation type, filtered to genetic perturbations only. (right) colored by time. Generating synthetic data splits To create test/train/val splits, use the script: python create_data_splits.py --data ../data/synthetic_data.h5 --out ../output/ --prop 0.7 See $ python create_data_splits --help for command line options. Creating train/test/val datasets The last step before we can move on to model training is to do the necessary pre-processing and create data splits. This can be done with: $ python SynthDataPreprocessing.py --input ../data/synthetic_data.h5 --output ../data/synthetic_data_PREPROC.h5 See $ python SynthDataPreprocessing.py --help for command line options This will produce a .h5 file with the following structure: cell_model GRN_removed_edges <HDF5 dataset \"cell_line_0\": shape (6, 2), type \"|S3\"> <HDF5 dataset \"cell_line_1\": shape (9, 2), type \"|S3\"> <HDF5 dataset \"cell_line_2\": shape (8, 2), type \"|S3\"> <HDF5 dataset \"cell_line_3\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_line_4\": shape (12, 2), type \"|S3\"> <HDF5 dataset \"cell_line_5\": shape (10, 2), type \"|S3\"> <HDF5 dataset \"cell_line_6\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_line_7\": shape (10, 2), type \"|S3\"> <HDF5 dataset \"cell_line_8\": shape (6, 2), type \"|S3\"> <HDF5 dataset \"labels\": shape (10,), type \"|S11\"> <HDF5 dataset \"onehot\": shape (137940, 10), type \"<f4\"> global_graph KD <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> KO <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> OE <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> agonist <HDF5 dataset \"node_names\": shape (5,), type \"|S9\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 7), type \"<i8\"> inhibitor <HDF5 dataset \"node_names\": shape (5,), type \"|S11\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 18), type \"<i8\"> protein activates protein <HDF5 dataset \"edge_index\": shape (2, 66), type \"<i8\"> inhibits protein <HDF5 dataset \"edge_index\": shape (2, 59), type \"<i8\"> <HDF5 dataset \"node_names\": shape (100,), type \"|S4\"> pert <HDF5 dataset \"conc_um\": shape (137940,), type \"|S46\"> <HDF5 dataset \"pert_name\": shape (137940,), type \"|S24\"> <HDF5 dataset \"pert_type\": shape (137940,), type \"|S20\"> protein <HDF5 dataset \"x\": shape (137940, 100), type \"<f8\"> <HDF5 dataset \"y\": shape (137940, 100), type \"<f8\"> time <HDF5 dataset \"max_time\": shape (), type \"<f8\"> <HDF5 dataset \"time\": shape (137940,), type \"<f8\"> References Schaffter T, Marbach D, Floreano D. GeneNetWeaver: in silico benchmark generation and performance profiling of network inference methods. Bioinformatics. 2011 Aug 15;27(16):2263-70. doi: 10.1093/bioinformatics/btr373. Epub 2011 Jun 22. PMID: 21697125.","title":"Generating a Synthetic Dataset"},{"location":"01_synth_data/generation/#synthetic-data-model","text":"We use the GeneNetWeaver package to simulate synthetic data Figure 1 : GeneNetWeaver graphic from the original paper. We focus on package elements illustrated by section B. source . To simulate data for initial model training and evaluation, we have extended the GeneNetWeaver package (1) , which uses ordinary differential equations (ODEs) built from a gene regulatory network (GRN) to simulate bulk mRNA gene expression under a variety of conditions. GNW outputs include: cell line steady state gene expression in the absence of any perturbation and gene expression time series after the introduction of genetic or chemical perturbation. GNW uses ODEs of the form: \\[ \\frac{dx_i}{dt} = m_i f_i(y) - \\lambda_i^{RNA} x_i \\] \\[ \\frac{dy_i}{dt} = r_i x_i - \\lambda_i^{PROT} y_i \\] Where \\(x_i\\) is RNA gene expression. \\(y_i\\) is protein abundance. \\(m_i\\) and \\(r_i\\) are production rates. \\(f_i(y)\\) is a function of transcription factor activation and \\(\\lambda\\) represents respective degradation rates. Subscript \\(i\\) represents the respective gene index. Building upon the GNW method, we simulate knockout\u2019s (KO) by setting to zero, knockdown\u2019s (KD) by setting to half its original value and over-expression (OE) by setting to twice it\u2019s original value. Chemical perturbations are simulated by randomly sampling a set of gene targets and respective dissociation constants and modifying the target gene values according to the equation: \\[ m_i^{perturbed} = m_i \\pm \\frac{m_i}{1+\\frac{k_d}{c}} \\] Where \\(k_d\\) represents dissociation constant and c is concentration in micro-molars. We simulate multi-drug combinations by modifying the union of drug targets. Drug target collisions are handled by either... Same drug types (2-agent combination): $$ m_i^{perturberd} = m \\pm m_i * \\frac{c_1}{c_1 + k_{d,1}(1 + \\frac{c_2}{k_{d,2}})} $$ Different drug types (2-agent combination): $$ m_i^{perturberd} = \\frac{m_i^{agonist} + m_i^{inhibitor}}{2} $$ We note the accepted scientific premise of pharmacological binding is that a drug binds to protein and stabilizes an active or inactive conformation. This premise suggests that a logical extension would be the modification of protein abundance or transcription factor activation; However, in practice we find that our approach to drug simulation creates reasonable outputs and captures many aspects of true drug perturbation behavior. Different cell contexts (such as cell type, patient, disease, etc.) have varying GRNs, which result in unique expression steady states and perturbation response. To emulate this behavior, we simulate each cellular context by creating a similar - but distinct \u2013 GRN prior to GNW simulation. Cellular context GRNs are created by randomly removing a subset of edges from the original parent GRN. This modified GRN becomes input to the GNW simulation. This work provides a tool for simulating the LINCS L1000 datatypes. Importantly, the data produced by this method is mediated by an underlying GRN, which makes graph-based methods uniquely suited to modeling the data.","title":"Synthetic Data Model"},{"location":"01_synth_data/generation/#generating-synthetic-data","text":"For a detailed walk-through of synthetic data pipeline, see gnnCDR/examples/gnw_tutorial.ipynb","title":"Generating Synthetic Data"},{"location":"01_synth_data/generation/#settings","text":"Modify the local settings.txt file, which must be stored in the .../gnnCDR/gnn_cdr/gnw/gnw/settings.txt The relevant parameters to modify include... # ideal-waddle Relevant parameters # Default max duration time in time-series experiments (must be consistent with numTimePoints_ and dt_) maxtTimeSeries = 500 # Time step for the time series (numTimePoints_ = (int) Math.round(maxtTimeSeries/dt) + 1) dt = 50 # Number of cell line models to create (n-1 single gene KO models + original) n_cell_lines = 10 # probability of edge removal when making cell line models prob_remove = 0.1 # Graph name to use as base PPI network # InSilicoSize100-Ecoli1.tsv graph_name = InSilicoSize100-Ecoli1.tsv # Number of agonist drugs to create num_agonists = 5 # Number of inhibitor drugs to create num_inhibitors = 5 # minimum concentration to use for drug simulations, intended to be in units log10(uM) min_log_conc = -5 # max conc \"\"\" max_log_conc = 1 # number of concentrations to simulate, spread evenly from min_log_conc to max_log_conc on a log scale num_dose_pts = 5 # The expectation (mean) of the number of targets each drug has. Targets are assigned probabalistically so some will have more and some will have fewer. expected_targs = 2 # minimum dissociation constant (kd) value to assign to drug targets (units of log(uM)) min_kd = -3 # max binding affinity max_kd = 0","title":"Settings"},{"location":"01_synth_data/generation/#usage","text":"To simulate data and produce the desired hdf5 file, first update the settings.txt file found in gnn_cdr/gnw/gnw/ to reflect your desired parameters. Next, navigate to the scripts directory and run: (gnnCDR) $ python create_synthetic_data.py --gnw_cwd ../gnn_cdr/gnw/gnw/ --out ../synthetic_data.h5 For command line options, use --help .","title":"Usage"},{"location":"01_synth_data/generation/#output","text":"The resulting hdf5 file will have the following general structure: ################################################## Printing HDF5 output structure. ################################################## baseline <HDF5 dataset \"cell_lines\": shape (25,), type \"|S12\"> <HDF5 dataset \"expr\": shape (25, 100), type \"<f8\"> graphs PPI <HDF5 dataset \"edge_attr\": shape (125, 2), type \"<f8\"> <HDF5 dataset \"edge_index\": shape (2, 125), type \"<i4\"> <HDF5 dataset \"edge_labels\": shape (2,), type \"|O\"> PTI <HDF5 dataset \"binding_affinity\": shape (120,), type \"<f8\"> <HDF5 dataset \"edge_attr\": shape (120, 5), type \"<i8\"> <HDF5 dataset \"edge_index\": shape (2, 120), type \"<i8\"> <HDF5 dataset \"edge_labels\": shape (5,), type \"|O\"> labels <HDF5 dataset \"drug_names\": shape (88,), type \"|S11\"> <HDF5 dataset \"gene_names\": shape (100,), type \"|S4\"> meta cell_models <HDF5 dataset \"cell_line_0\": shape (9, 2), type \"|S3\"> <HDF5 dataset \"cell_line_1\": shape (10, 2), type \"|S3\"> ... <HDF5 dataset \"cell_line_8\": shape (7, 2), type \"|S3\"> <HDF5 dataset \"cell_line_9\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_models_info\": shape (1,), type \"|S54\"> <HDF5 dataset \"creation_date\": shape (), type \"|O\"> edgelist <HDF5 dataset \"annot\": shape (125,), type \"|S1\"> <HDF5 dataset \"from\": shape (125,), type \"|S3\"> <HDF5 dataset \"to\": shape (125,), type \"|S4\"> <HDF5 dataset \"settings\": shape (), type \"|O\"> perts <HDF5 dataset \"cell_line\": shape (344850,), type \"|S12\"> <HDF5 dataset \"conc_um\": shape (344850,), type \"|S46\"> <HDF5 dataset \"expr\": shape (344850, 100), type \"<f8\"> <HDF5 dataset \"pert_kd\": shape (344850,), type \"|S260\"> <HDF5 dataset \"pert_name\": shape (344850,), type \"|S24\"> <HDF5 dataset \"pert_targ\": shape (344850,), type \"|S58\"> <HDF5 dataset \"pert_type\": shape (344850,), type \"|S20\"> <HDF5 dataset \"time\": shape (344850,), type \"<f8\">","title":"Output"},{"location":"01_synth_data/generation/#output-pca","text":"(left) Colored by cell context (middle) colored by perturbation type, filtered to genetic perturbations only. (right) colored by time.","title":"Output PCA"},{"location":"01_synth_data/generation/#generating-synthetic-data-splits","text":"To create test/train/val splits, use the script: python create_data_splits.py --data ../data/synthetic_data.h5 --out ../output/ --prop 0.7 See $ python create_data_splits --help for command line options.","title":"Generating synthetic data splits"},{"location":"01_synth_data/generation/#creating-traintestval-datasets","text":"The last step before we can move on to model training is to do the necessary pre-processing and create data splits. This can be done with: $ python SynthDataPreprocessing.py --input ../data/synthetic_data.h5 --output ../data/synthetic_data_PREPROC.h5 See $ python SynthDataPreprocessing.py --help for command line options This will produce a .h5 file with the following structure: cell_model GRN_removed_edges <HDF5 dataset \"cell_line_0\": shape (6, 2), type \"|S3\"> <HDF5 dataset \"cell_line_1\": shape (9, 2), type \"|S3\"> <HDF5 dataset \"cell_line_2\": shape (8, 2), type \"|S3\"> <HDF5 dataset \"cell_line_3\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_line_4\": shape (12, 2), type \"|S3\"> <HDF5 dataset \"cell_line_5\": shape (10, 2), type \"|S3\"> <HDF5 dataset \"cell_line_6\": shape (5, 2), type \"|S3\"> <HDF5 dataset \"cell_line_7\": shape (10, 2), type \"|S3\"> <HDF5 dataset \"cell_line_8\": shape (6, 2), type \"|S3\"> <HDF5 dataset \"labels\": shape (10,), type \"|S11\"> <HDF5 dataset \"onehot\": shape (137940, 10), type \"<f4\"> global_graph KD <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> KO <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> OE <HDF5 dataset \"node_names\": shape (26,), type \"|S6\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 26), type \"<i8\"> agonist <HDF5 dataset \"node_names\": shape (5,), type \"|S9\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 7), type \"<i8\"> inhibitor <HDF5 dataset \"node_names\": shape (5,), type \"|S11\"> targets protein <HDF5 dataset \"edge_index\": shape (2, 18), type \"<i8\"> protein activates protein <HDF5 dataset \"edge_index\": shape (2, 66), type \"<i8\"> inhibits protein <HDF5 dataset \"edge_index\": shape (2, 59), type \"<i8\"> <HDF5 dataset \"node_names\": shape (100,), type \"|S4\"> pert <HDF5 dataset \"conc_um\": shape (137940,), type \"|S46\"> <HDF5 dataset \"pert_name\": shape (137940,), type \"|S24\"> <HDF5 dataset \"pert_type\": shape (137940,), type \"|S20\"> protein <HDF5 dataset \"x\": shape (137940, 100), type \"<f8\"> <HDF5 dataset \"y\": shape (137940, 100), type \"<f8\"> time <HDF5 dataset \"max_time\": shape (), type \"<f8\"> <HDF5 dataset \"time\": shape (137940,), type \"<f8\">","title":"Creating train/test/val datasets"},{"location":"01_synth_data/generation/#references","text":"Schaffter T, Marbach D, Floreano D. GeneNetWeaver: in silico benchmark generation and performance profiling of network inference methods. Bioinformatics. 2011 Aug 15;27(16):2263-70. doi: 10.1093/bioinformatics/btr373. Epub 2011 Jun 22. PMID: 21697125.","title":"References"},{"location":"02_real_data/_old/","text":"Encoding Options First 5 rows of our pandas dataframe. ensembl cell_iname Variant_Classification Variant_Type Variant_annotation isDeleterious ENSG00000008128 HL60 Missense_Mutation SNP other non-conserving False ENSG00000142611 HL60 Missense_Mutation SNP other non-conserving False ENSG00000179163 HL60 Missense_Mutation SNP other non-conserving False ENSG00000126705 HL60 Missense_Mutation SNP other non-conserving False ENSG00000162526 HL60 Silent SNP silent False Feature: CGA_WES_AC For all columns with AC, the allelic ratio is presented as [ALTERNATE:REFERENCE]. CGA_WES_AC: the allelic ratio for this variant in all our WES/WGS(exon only) using a cell line adapted version of the 2019 CGA pipeline that includes germline filtering. source . 22% of observations have NA values for this feature. Feature: Variant_Classification Translational effect of variant allele source Variant_Classification count Missense_Mutation 123884 Silent 53541 Frame_Shift_Del 11449 Splice_Site 8215 Nonsense_Mutation 7608 Frame_Shift_Ins 5298 In_Frame_Del 1014 De_novo_Start_OutOfFrame 826 In_Frame_Ins 224 Start_Codon_SNP 196 Nonstop_Mutation 149 Intron 116 IGR 39 Stop_Codon_Del 34 Stop_Codon_Ins 22 5'Flank 19 Start_Codon_Del 17 5'UTR 13 3'UTR 13 Start_Codon_Ins 9 Feature: Variant_annotation No Depmap information available on this feature. This biostars thread offers some insight: [ A. Domingues ] \"Got the answer in the Forum of DepMap (closed access). I am pasting here the crucial part of the answer. If any one from DepMap has an issue with it, I am happy to remove it: We use Oncotator to annotate the mutations. The output of this tool is stored in the \u2018Variant_Classification\u2019 column of the mutation maf file The Variant_annotation column in the CCLE_mutations.csv MAF file We have added a Variant_annotation column in the DepMap mutation data, CCLE_mutations.csv 4, which groups mutations using more inclusive definitions. The Variant_annotation column labels a mutation as \u201cdamaging\u201d, \u201cother non-conserving\u201d, \u201cother conserving\u201d or \u201csilent\u201d using the Variant_Classification column and the definitions below.\" Oncotator information here . Variation count other non-conserving 125327 silent 53541 damaging 33618 other conserving 200 Feature: Variant_Type Type of mutation. TNP (tri-nucleotide polymorphism) is analogous to DNP (di-nucleotide polymorphism) but for three consecutive nucleotides. ONP (oligo-nucleotide polymorphism) is analogous to TNP but for consecutive runs of four or more (SNP, DNP, TNP, ONP, INS, DEL, or Consolidated) source Variant_Type count SNP 193588 DEL 13119 INS 5907 DNP 72 Feature: isDeleterious No DepMap information available on this feature This appears to be outdated, and \"Variant_annotation\" is suggested for replacement information. See this thread . isDeleterious count 0 False 178872 1 True 33814","title":"Encoding Options"},{"location":"02_real_data/_old/#encoding-options","text":"First 5 rows of our pandas dataframe. ensembl cell_iname Variant_Classification Variant_Type Variant_annotation isDeleterious ENSG00000008128 HL60 Missense_Mutation SNP other non-conserving False ENSG00000142611 HL60 Missense_Mutation SNP other non-conserving False ENSG00000179163 HL60 Missense_Mutation SNP other non-conserving False ENSG00000126705 HL60 Missense_Mutation SNP other non-conserving False ENSG00000162526 HL60 Silent SNP silent False","title":"Encoding Options"},{"location":"02_real_data/_old/#feature-cga_wes_ac","text":"For all columns with AC, the allelic ratio is presented as [ALTERNATE:REFERENCE]. CGA_WES_AC: the allelic ratio for this variant in all our WES/WGS(exon only) using a cell line adapted version of the 2019 CGA pipeline that includes germline filtering. source . 22% of observations have NA values for this feature.","title":"Feature: CGA_WES_AC"},{"location":"02_real_data/_old/#feature-variant_classification","text":"Translational effect of variant allele source Variant_Classification count Missense_Mutation 123884 Silent 53541 Frame_Shift_Del 11449 Splice_Site 8215 Nonsense_Mutation 7608 Frame_Shift_Ins 5298 In_Frame_Del 1014 De_novo_Start_OutOfFrame 826 In_Frame_Ins 224 Start_Codon_SNP 196 Nonstop_Mutation 149 Intron 116 IGR 39 Stop_Codon_Del 34 Stop_Codon_Ins 22 5'Flank 19 Start_Codon_Del 17 5'UTR 13 3'UTR 13 Start_Codon_Ins 9","title":"Feature: Variant_Classification"},{"location":"02_real_data/_old/#feature-variant_annotation","text":"No Depmap information available on this feature. This biostars thread offers some insight: [ A. Domingues ] \"Got the answer in the Forum of DepMap (closed access). I am pasting here the crucial part of the answer. If any one from DepMap has an issue with it, I am happy to remove it: We use Oncotator to annotate the mutations. The output of this tool is stored in the \u2018Variant_Classification\u2019 column of the mutation maf file The Variant_annotation column in the CCLE_mutations.csv MAF file We have added a Variant_annotation column in the DepMap mutation data, CCLE_mutations.csv 4, which groups mutations using more inclusive definitions. The Variant_annotation column labels a mutation as \u201cdamaging\u201d, \u201cother non-conserving\u201d, \u201cother conserving\u201d or \u201csilent\u201d using the Variant_Classification column and the definitions below.\" Oncotator information here . Variation count other non-conserving 125327 silent 53541 damaging 33618 other conserving 200","title":"Feature: Variant_annotation"},{"location":"02_real_data/_old/#feature-variant_type","text":"Type of mutation. TNP (tri-nucleotide polymorphism) is analogous to DNP (di-nucleotide polymorphism) but for three consecutive nucleotides. ONP (oligo-nucleotide polymorphism) is analogous to TNP but for consecutive runs of four or more (SNP, DNP, TNP, ONP, INS, DEL, or Consolidated) source Variant_Type count SNP 193588 DEL 13119 INS 5907 DNP 72","title":"Feature: Variant_Type"},{"location":"02_real_data/_old/#feature-isdeleterious","text":"No DepMap information available on this feature This appears to be outdated, and \"Variant_annotation\" is suggested for replacement information. See this thread . isDeleterious count 0 False 178872 1 True 33814","title":"Feature: isDeleterious"},{"location":"02_real_data/cnv/","text":"Copy Number Variation (CNV) Gene-level copy number data that is log2 transformed with a pseudo-count of 1; log2(CN ratio + 1). Genes:25368 Cell Lines:1754 Primary Diseases:35 Lineages:38 Source: Broad Institute DepMap readme . Reactome FI coverage # cnv genes: 24004 # FI genes: 13609 # CNV,FI genes that overlap: 13407 [98.5%] Cell line coverage There are 132 cell lines with DepMap_ID -> cell_iname mappings that also have coverage in i) Lincs ii) CCLE expr and iii) CCLE mutation . NOTE: Previous CCLE & Lincs cell line overlap was 133 but cell line ( cell_iname ) HCC1588 is not in the CNV dataset. Fortunately, HCC1588 only has 308 observations in LINCS (after QC), and therefore we feel comfortable dropping this line from our analysis. To see this list of overlapping lines, refer to: gnnCDR/gnn_cdr/depmap/eda/lincs_expr_mut_cnv_cell_inames.txt Missing CNV values There are a small subset (~0.001%) of NA values in this dataset. NA elements are assigned a value of 1. CNV historgam Pre-processing CNV data Genes in the reactome FI network that are not in the CNV dataset are assigned a value of 1. All CNV values are then scaled between 0-1. Implementation To load the data: cnv = gnn_cdr.depmap.load_ccle_cnv(verbose=True) output: # of genes lost in XXX -> ensembl mapping (columns): 1420 # of cell lines lost cin DepMap_ID -> cell_iname mapping (rows): 1618 [Final] Number of genes: 24004 [Final] Number of cell lines: 136 To get an individual cell lines CNV data: max_cnv_val = cnv[cnv.columns[1:]].values.ravel().max() x = gnn_cdr.depmap.get_cell_line_ccle_cnv(cnv, cell_line='HEPG2', genelist=nodelist_fi, max_cnv_val=max_cnv_val) x.shape output: (13639,)","title":"Copy Number Variation (CNV)"},{"location":"02_real_data/cnv/#copy-number-variation-cnv","text":"Gene-level copy number data that is log2 transformed with a pseudo-count of 1; log2(CN ratio + 1). Genes:25368 Cell Lines:1754 Primary Diseases:35 Lineages:38 Source: Broad Institute DepMap readme .","title":"Copy Number Variation (CNV)"},{"location":"02_real_data/cnv/#reactome-fi-coverage","text":"# cnv genes: 24004 # FI genes: 13609 # CNV,FI genes that overlap: 13407 [98.5%]","title":"Reactome FI coverage"},{"location":"02_real_data/cnv/#cell-line-coverage","text":"There are 132 cell lines with DepMap_ID -> cell_iname mappings that also have coverage in i) Lincs ii) CCLE expr and iii) CCLE mutation . NOTE: Previous CCLE & Lincs cell line overlap was 133 but cell line ( cell_iname ) HCC1588 is not in the CNV dataset. Fortunately, HCC1588 only has 308 observations in LINCS (after QC), and therefore we feel comfortable dropping this line from our analysis. To see this list of overlapping lines, refer to: gnnCDR/gnn_cdr/depmap/eda/lincs_expr_mut_cnv_cell_inames.txt","title":"Cell line coverage"},{"location":"02_real_data/cnv/#missing-cnv-values","text":"There are a small subset (~0.001%) of NA values in this dataset. NA elements are assigned a value of 1.","title":"Missing CNV values"},{"location":"02_real_data/cnv/#cnv-historgam","text":"","title":"CNV historgam"},{"location":"02_real_data/cnv/#pre-processing-cnv-data","text":"Genes in the reactome FI network that are not in the CNV dataset are assigned a value of 1. All CNV values are then scaled between 0-1.","title":"Pre-processing CNV data"},{"location":"02_real_data/cnv/#implementation","text":"To load the data: cnv = gnn_cdr.depmap.load_ccle_cnv(verbose=True) output: # of genes lost in XXX -> ensembl mapping (columns): 1420 # of cell lines lost cin DepMap_ID -> cell_iname mapping (rows): 1618 [Final] Number of genes: 24004 [Final] Number of cell lines: 136 To get an individual cell lines CNV data: max_cnv_val = cnv[cnv.columns[1:]].values.ravel().max() x = gnn_cdr.depmap.get_cell_line_ccle_cnv(cnv, cell_line='HEPG2', genelist=nodelist_fi, max_cnv_val=max_cnv_val) x.shape output: (13639,)","title":"Implementation"},{"location":"02_real_data/dti_graph/","text":"Drug-Target Interaction Graph To map drug effect to protein targets we will use the CLUE compound datasets. Data source , More information can be found here . This is a bi-partite graph, which maps drug nodes to protein nodes. After filtering to drug targets contained in the reactome FI network, we calculate the general characteristics: min # targs 1 max # targs 96 median # targs 1.0 mean # targs 2.5294306851077515 Edge Annotation Feature Encoding Similar to edge annotation encoding used for the FI network, we will use word presence to encode drug mechanism of action (MOA). Here are the top 10 most frequent MOA words. MOA WORD # DRUGS W/ MOA WORD --------------------------------------- inhibitor 1903 receptor 1434 antagonist 792 agonist 650 serotonin 176 channel 161 kinase 152 adrenergic 148 dopamine 133 blocker 123 The full list of drug MOA words and there respective count (by drug) can be found here . We will use the top N [???] most common MOA words as DTI edge features; Recognizably, this may lead to some drugs having no word presence (e.g., zero vector edge features) and therefore we should be cognizant of the convolution type that we use such that zero vectored edge features will still be capable of learning a pertubation effect. Using the top 50 most common MOA words, we can create edge_attr vector with binary label counts: This graph shows that (using top 50 most common MOA words) we will have 200 \"zero-vectored\" edges, e.g., edges that have no MOA word presence. Implementation edge_index, edge_attr, drug_nodelist, moa_words = gnn_cdr.lincs.create_CLUE_dti_graph(fi_nodelist, n_moa_feats=50) output: # na targets: 31275 # of targets without ensemble protein id: 1 # of targets not in id list: 181 [FINAL] # of targets,drugs: (7864, 3109)","title":"Drug-Target Interaction Network"},{"location":"02_real_data/dti_graph/#drug-target-interaction-graph","text":"To map drug effect to protein targets we will use the CLUE compound datasets. Data source , More information can be found here . This is a bi-partite graph, which maps drug nodes to protein nodes. After filtering to drug targets contained in the reactome FI network, we calculate the general characteristics: min # targs 1 max # targs 96 median # targs 1.0 mean # targs 2.5294306851077515","title":"Drug-Target Interaction Graph"},{"location":"02_real_data/dti_graph/#edge-annotation-feature-encoding","text":"Similar to edge annotation encoding used for the FI network, we will use word presence to encode drug mechanism of action (MOA). Here are the top 10 most frequent MOA words. MOA WORD # DRUGS W/ MOA WORD --------------------------------------- inhibitor 1903 receptor 1434 antagonist 792 agonist 650 serotonin 176 channel 161 kinase 152 adrenergic 148 dopamine 133 blocker 123 The full list of drug MOA words and there respective count (by drug) can be found here . We will use the top N [???] most common MOA words as DTI edge features; Recognizably, this may lead to some drugs having no word presence (e.g., zero vector edge features) and therefore we should be cognizant of the convolution type that we use such that zero vectored edge features will still be capable of learning a pertubation effect. Using the top 50 most common MOA words, we can create edge_attr vector with binary label counts: This graph shows that (using top 50 most common MOA words) we will have 200 \"zero-vectored\" edges, e.g., edges that have no MOA word presence.","title":"Edge Annotation Feature Encoding"},{"location":"02_real_data/dti_graph/#implementation","text":"edge_index, edge_attr, drug_nodelist, moa_words = gnn_cdr.lincs.create_CLUE_dti_graph(fi_nodelist, n_moa_feats=50) output: # na targets: 31275 # of targets without ensemble protein id: 1 # of targets not in id list: 181 [FINAL] # of targets,drugs: (7864, 3109)","title":"Implementation"},{"location":"02_real_data/expression/","text":"Cancer Cell Line Encyclopedia unperturbed RNA-seq expression Data source and info We will use the CCLE expression dataset, which can be downloaded here , more info here . From DepMap: Gene expression TPM values of the protein coding genes for DepMap cell lines. Values are inferred from RNA-seq data using the RSEM tool and are reported after log2 transformation, using a pseudo-count of 1; log2(TPM+1). Additional RNA-seq-based expression measurements are available for download as part of the full DepMap Data Release More information on the DepMap Omics processing pipeline is available at https://github.com/broadinstitute/depmap_omics. Genes:19177 Cell Lines:1393 Primary Diseases:33 Lineages:38 Source: Broad Institute Reactome FI Coverage There are 403 ccle gene's lost in the mapping from gene symbol to ensembl. 13373 of 13609 reactome FI genes have coverage in CCLE expression dataset (98% coverage). LINCS Coverage Of the total cell lines in LINCS (n=239), 133 of them have CCLE expression data (56%); However, these 133 lines make up the majority of observations in LINCS L1000. After filtering observations that did not pass QC, these 133 lines with CCLE expression coverage made up 1.83/2.16 million LINCS observations (85%). Z-score transformation To make imputation and gene-to-gene expression more comparable for our GNN we will perform z-score tranformations: \\[ zscore(x) = \\frac{x - \\bar{x}}{\\sigma^2} \\] Here is a visualization of the original and transformed distributions: This can be done using the function: expr = gnn_cdr.depmap.load_ccle_expr(zscore=True) Accessing individual cell line expression We can get a specific cell lines expression by using the method: x = gnn_cdr.depmap.get_cell_line_ccle_expr(expr, cell_line, genelist) where: expr is the pandas dataframe returned by load_ccle_expr cell_line is the cell_iname identifier genelist is the list of genes to return; note, genes that are in genelist but not in expr will be zero imputed.","title":"Expression"},{"location":"02_real_data/expression/#cancer-cell-line-encyclopedia-unperturbed-rna-seq-expression","text":"","title":"Cancer Cell Line Encyclopedia unperturbed RNA-seq expression"},{"location":"02_real_data/expression/#data-source-and-info","text":"We will use the CCLE expression dataset, which can be downloaded here , more info here . From DepMap: Gene expression TPM values of the protein coding genes for DepMap cell lines. Values are inferred from RNA-seq data using the RSEM tool and are reported after log2 transformation, using a pseudo-count of 1; log2(TPM+1). Additional RNA-seq-based expression measurements are available for download as part of the full DepMap Data Release More information on the DepMap Omics processing pipeline is available at https://github.com/broadinstitute/depmap_omics. Genes:19177 Cell Lines:1393 Primary Diseases:33 Lineages:38 Source: Broad Institute","title":"Data source and info"},{"location":"02_real_data/expression/#reactome-fi-coverage","text":"There are 403 ccle gene's lost in the mapping from gene symbol to ensembl. 13373 of 13609 reactome FI genes have coverage in CCLE expression dataset (98% coverage).","title":"Reactome FI Coverage"},{"location":"02_real_data/expression/#lincs-coverage","text":"Of the total cell lines in LINCS (n=239), 133 of them have CCLE expression data (56%); However, these 133 lines make up the majority of observations in LINCS L1000. After filtering observations that did not pass QC, these 133 lines with CCLE expression coverage made up 1.83/2.16 million LINCS observations (85%).","title":"LINCS Coverage"},{"location":"02_real_data/expression/#z-score-transformation","text":"To make imputation and gene-to-gene expression more comparable for our GNN we will perform z-score tranformations: \\[ zscore(x) = \\frac{x - \\bar{x}}{\\sigma^2} \\] Here is a visualization of the original and transformed distributions: This can be done using the function: expr = gnn_cdr.depmap.load_ccle_expr(zscore=True)","title":"Z-score transformation"},{"location":"02_real_data/expression/#accessing-individual-cell-line-expression","text":"We can get a specific cell lines expression by using the method: x = gnn_cdr.depmap.get_cell_line_ccle_expr(expr, cell_line, genelist) where: expr is the pandas dataframe returned by load_ccle_expr cell_line is the cell_iname identifier genelist is the list of genes to return; note, genes that are in genelist but not in expr will be zero imputed.","title":"Accessing individual cell line expression"},{"location":"02_real_data/fi_graph/","text":"Creating a Global Graph using the Reactome Functional Interaction (FI) network We will create a global graph (e.g., a graph spanning all protein/gene entities; used as parent for individual perturbation subgraphs) using the functional interaction (FI) network provided by (1). The FI network provided by Wu et. al, aims at constructing a pathway-based analysis system. To do this they: \"Construct a protein functional interaction network by extending curated pathways with non-curated sources of information, including protein-protein interactions, gene coexpression, protein domain interaction, Gene Ontology (GO) annotations and text-mined protein interactions, which cover close to 50% of the human proteome\" (1). More recent database updates have been provided, which has improved the proteome coverage. The data and information can be found here . We plan to use the most recent version, as of 3/8/22 we are using Version 2021 . For this network, we make the assumption that each gene -> rna -> protein maps 1:1:1 and therefore we can collapse genes, rna and protein into a single node, which represents the state of all 3. Furthermore, this allows complex edge interactions beyond merely protein-protein interactions or gene regulatory information. Data Format The reactome FI data is provided in the form of edge list with features: Annotation: The edge type(s) Direction: The edge direction [-,|,<,>] Score: Edge confidence, only applicable if the edge is predicted. Gene1 Gene2 Annotation Direction Score Gene1_ensembl Gene2_ensembl 16-5-5 CDC42 predicted - 0.97 None ENSG00000070831 16-5-5 PARD3 predicted - 1.00 None ENSG00000148498 16-5-5 PARD3B predicted - 1.00 None ENSG00000116117 A1CF APOBEC1 catalyzed by; complex; input <- 1.00 ENSG00000148584 ENSG00000111701 A1CF EP300 expression regulated by <- 1.00 ENSG00000148584 ENSG00000100393 Top 10 most common edge annotations and directions. As you can see, the edge annotation can include multiple labels. Annotation Direction Count -------------------------------------------------------------- complex; input - 64959 predicted - 40443 complex - 17248 catalyzed by <- 11145 catalyze -> 9563 input - 8240 catalyze; catalyzed by; complex; input <-> 7707 activate -> 5658 activated by <- 5558 catalyze; catalyzed by; input <-> 5476 Network Characteristics NOTE : We filter to the largest connected component. Number of Nodes: 13751 Number of Edges: 257629 Average Cluster Coef: 0.38 Network Density: 0.003 Overlap with LINCS L1000 platform Data source NOTE: for this EDA we use the largest component. To understand the overlap between L1000 genes and Reactome FI entities, we map the overlapping sets and compare. The L1000 dataset has 3 data subsets: landmark : ~1000 genes RNA abundance explictly measured using a Luminex bead assay, more info here . inferred : ~2000 genes with inferred RNA abundance, but not apart of the best inferred subset. Lower accuracy estimates. best infered : ~9000 genes with high confidence inferred RNA abundance. To map genes between reactome FI and LINCS L1000 genes, we use ensembl gene identifiers - which does not have perfect mapping (e.g., we lose some genes in mapping from XXX -> enesmbl). ############ landmark ############# # of lincs genes dropped in ensembl mapping: 10 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 968 # reactome genes: 13609 # overlapping genes (lincs & reactome) 837 percentage of reactome: 6.2 percentage of lincs: 86.5 ############ best inferred ############# # of lincs genes dropped in ensembl mapping: 129 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 9067 # reactome genes: 13609 # overlapping genes (lincs & reactome) 7394 percentage of reactome: 54.3 percentage of lincs: 81.5 ############ all ############# # of lincs genes dropped in ensembl mapping: 187 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 12140 # reactome genes: 13609 # overlapping genes (lincs & reactome) 9808 percentage of reactome: 72.1 percentage of lincs: 80.8 Overlap with CLUE compound information Data source , More information can be found here . To ensure that we have drug -> protein overlap in our reactome FI graph we convert all protein targets from the CLUE compound information dataset to ensembl genes and compare the overlap in reactome FI network. # NA target observations (filtered): 31275 # of targets without ensembl id: 1 # of targets not in reactome FI network: 181 # of targets in reactome FI network: 7864 # of drugs in reactome FI network: 3109 # of unique drugs targets in FI network: 836 Of note, cmap_name is not a 1:1 mapping with pert_id . Edge Annotation Feature Encoding Word annotation features are encoded as binary variable word presences, e.g., if a word is present in the annotation, then that label has a 1 value, otherwise 0. NOTE: this is \"hot-encoding\" but not \"one-hot encoding\"; edges can have multiple annotations. example: edge annotation: \"catalyzed by; complex; input\" annot. word list: ['catalyzed', 'complex', 'input', 'random'] edge feature: [1,1,1,0] See below a the edge annotation word list and respective word frequencies across all edges in the FI network. word label -------------------- Frequency % (across all edges) __________________________________________________________ methylation ------------------- 0.0019 glycosylation ----------------- 0.0037 glycosylated ------------------ 0.0044 dephosphorylated -------------- 0.0063 state ------------------------- 0.0102 change ------------------------ 0.0102 repression -------------------- 0.0183 repressed --------------------- 0.0197 ubiquitinated ----------------- 0.0348 interaction ------------------- 0.0565 dissociation ------------------ 0.0655 ubiquitination ---------------- 0.0911 PCrel ------------------------- 0.2602 dephosphorylation ------------- 0.3221 phosphorylated ---------------- 0.5218 inhibition -------------------- 0.9153 ECrel ------------------------- 0.9411 effect ------------------------ 1.0804 indirect ---------------------- 1.0912 GErel ------------------------- 1.1847 compound ---------------------- 1.2137 regulates --------------------- 1.3004 regulated --------------------- 1.4183 phosphorylation --------------- 1.6001 binding/association ----------- 2.4961 inhibited --------------------- 2.8101 activation -------------------- 2.8267 reaction ---------------------- 3.4820 inhibite ---------------------- 3.4847 expression -------------------- 3.7661 inhibit ----------------------- 4.9503 activated --------------------- 5.7617 activate ---------------------- 8.9841 PPrel ------------------------- 10.2082 catalyzed --------------------- 10.3590 catalyze ---------------------- 14.3489 predicted --------------------- 19.7095 input ------------------------- 47.3727 complex ----------------------- 49.8622 Edge Direction Encoding Our network is set up as a directed network and edge directionality is intended to be primarily specified by this mechanism. For bi-directional edges ('-' or '<->'), two opposing edges are included in our network. For some more complex edge annotations and directions (e.g., multiple edge annotations or alternate-type bi-directionality), encoding edge direction may be a useful feature. To do this, we will create 2 features that can have the possible values [-1,0,1]. Edge directions can be though of as 3 element string: left_char , center_char , right_char center_char is always '-' and therefore unnecessary to encode left_char can be \"|\" (-1) or \"<\" (1) or neither (0), this will be the first feature right_char can be \"|\" (-1) or \">\" (1) or neither (0), this will be the second feature The edge direction strings used in reactome FI network. Direction | Count | feature --------------------------------------- - | 144182 | [0,0] <- | 40858 | [1,0] -> | 39438 | [0,1] <-> | 13177 | [1,1] |- | 5499 | [-1,0] -| | 4690 | [0,-1] |-> | 1454 | [-1,1] <-| | 1107 | [1,-1] |-| | 79 | [-1,-1] Implementation The reactome FI network can be constructed by: edge_index, edge_attr, nodelist, annot_words = gnn_cdr.reactomefi.create_reactome_fi_graph() References Wu, G., Feng, X. & Stein, L. A human functional protein interaction network and its application to cancer data analysis. Genome Biol 11, R53 (2010). https://doi.org/10.1186/gb-2010-11-5-r53","title":"Functional Interaction Network"},{"location":"02_real_data/fi_graph/#creating-a-global-graph-using-the-reactome-functional-interaction-fi-network","text":"We will create a global graph (e.g., a graph spanning all protein/gene entities; used as parent for individual perturbation subgraphs) using the functional interaction (FI) network provided by (1). The FI network provided by Wu et. al, aims at constructing a pathway-based analysis system. To do this they: \"Construct a protein functional interaction network by extending curated pathways with non-curated sources of information, including protein-protein interactions, gene coexpression, protein domain interaction, Gene Ontology (GO) annotations and text-mined protein interactions, which cover close to 50% of the human proteome\" (1). More recent database updates have been provided, which has improved the proteome coverage. The data and information can be found here . We plan to use the most recent version, as of 3/8/22 we are using Version 2021 . For this network, we make the assumption that each gene -> rna -> protein maps 1:1:1 and therefore we can collapse genes, rna and protein into a single node, which represents the state of all 3. Furthermore, this allows complex edge interactions beyond merely protein-protein interactions or gene regulatory information.","title":"Creating a Global Graph using the Reactome Functional Interaction (FI) network"},{"location":"02_real_data/fi_graph/#data-format","text":"The reactome FI data is provided in the form of edge list with features: Annotation: The edge type(s) Direction: The edge direction [-,|,<,>] Score: Edge confidence, only applicable if the edge is predicted. Gene1 Gene2 Annotation Direction Score Gene1_ensembl Gene2_ensembl 16-5-5 CDC42 predicted - 0.97 None ENSG00000070831 16-5-5 PARD3 predicted - 1.00 None ENSG00000148498 16-5-5 PARD3B predicted - 1.00 None ENSG00000116117 A1CF APOBEC1 catalyzed by; complex; input <- 1.00 ENSG00000148584 ENSG00000111701 A1CF EP300 expression regulated by <- 1.00 ENSG00000148584 ENSG00000100393 Top 10 most common edge annotations and directions. As you can see, the edge annotation can include multiple labels. Annotation Direction Count -------------------------------------------------------------- complex; input - 64959 predicted - 40443 complex - 17248 catalyzed by <- 11145 catalyze -> 9563 input - 8240 catalyze; catalyzed by; complex; input <-> 7707 activate -> 5658 activated by <- 5558 catalyze; catalyzed by; input <-> 5476","title":"Data Format"},{"location":"02_real_data/fi_graph/#network-characteristics","text":"NOTE : We filter to the largest connected component. Number of Nodes: 13751 Number of Edges: 257629 Average Cluster Coef: 0.38 Network Density: 0.003","title":"Network Characteristics"},{"location":"02_real_data/fi_graph/#overlap-with-lincs-l1000-platform","text":"Data source NOTE: for this EDA we use the largest component. To understand the overlap between L1000 genes and Reactome FI entities, we map the overlapping sets and compare. The L1000 dataset has 3 data subsets: landmark : ~1000 genes RNA abundance explictly measured using a Luminex bead assay, more info here . inferred : ~2000 genes with inferred RNA abundance, but not apart of the best inferred subset. Lower accuracy estimates. best infered : ~9000 genes with high confidence inferred RNA abundance. To map genes between reactome FI and LINCS L1000 genes, we use ensembl gene identifiers - which does not have perfect mapping (e.g., we lose some genes in mapping from XXX -> enesmbl). ############ landmark ############# # of lincs genes dropped in ensembl mapping: 10 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 968 # reactome genes: 13609 # overlapping genes (lincs & reactome) 837 percentage of reactome: 6.2 percentage of lincs: 86.5 ############ best inferred ############# # of lincs genes dropped in ensembl mapping: 129 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 9067 # reactome genes: 13609 # overlapping genes (lincs & reactome) 7394 percentage of reactome: 54.3 percentage of lincs: 81.5 ############ all ############# # of lincs genes dropped in ensembl mapping: 187 # of reactome genes dropped in ensembl mapping: 344 # lincs genes: 12140 # reactome genes: 13609 # overlapping genes (lincs & reactome) 9808 percentage of reactome: 72.1 percentage of lincs: 80.8","title":"Overlap with LINCS L1000 platform"},{"location":"02_real_data/fi_graph/#overlap-with-clue-compound-information","text":"Data source , More information can be found here . To ensure that we have drug -> protein overlap in our reactome FI graph we convert all protein targets from the CLUE compound information dataset to ensembl genes and compare the overlap in reactome FI network. # NA target observations (filtered): 31275 # of targets without ensembl id: 1 # of targets not in reactome FI network: 181 # of targets in reactome FI network: 7864 # of drugs in reactome FI network: 3109 # of unique drugs targets in FI network: 836 Of note, cmap_name is not a 1:1 mapping with pert_id .","title":"Overlap with CLUE compound information"},{"location":"02_real_data/fi_graph/#edge-annotation-feature-encoding","text":"Word annotation features are encoded as binary variable word presences, e.g., if a word is present in the annotation, then that label has a 1 value, otherwise 0. NOTE: this is \"hot-encoding\" but not \"one-hot encoding\"; edges can have multiple annotations. example: edge annotation: \"catalyzed by; complex; input\" annot. word list: ['catalyzed', 'complex', 'input', 'random'] edge feature: [1,1,1,0] See below a the edge annotation word list and respective word frequencies across all edges in the FI network. word label -------------------- Frequency % (across all edges) __________________________________________________________ methylation ------------------- 0.0019 glycosylation ----------------- 0.0037 glycosylated ------------------ 0.0044 dephosphorylated -------------- 0.0063 state ------------------------- 0.0102 change ------------------------ 0.0102 repression -------------------- 0.0183 repressed --------------------- 0.0197 ubiquitinated ----------------- 0.0348 interaction ------------------- 0.0565 dissociation ------------------ 0.0655 ubiquitination ---------------- 0.0911 PCrel ------------------------- 0.2602 dephosphorylation ------------- 0.3221 phosphorylated ---------------- 0.5218 inhibition -------------------- 0.9153 ECrel ------------------------- 0.9411 effect ------------------------ 1.0804 indirect ---------------------- 1.0912 GErel ------------------------- 1.1847 compound ---------------------- 1.2137 regulates --------------------- 1.3004 regulated --------------------- 1.4183 phosphorylation --------------- 1.6001 binding/association ----------- 2.4961 inhibited --------------------- 2.8101 activation -------------------- 2.8267 reaction ---------------------- 3.4820 inhibite ---------------------- 3.4847 expression -------------------- 3.7661 inhibit ----------------------- 4.9503 activated --------------------- 5.7617 activate ---------------------- 8.9841 PPrel ------------------------- 10.2082 catalyzed --------------------- 10.3590 catalyze ---------------------- 14.3489 predicted --------------------- 19.7095 input ------------------------- 47.3727 complex ----------------------- 49.8622","title":"Edge Annotation Feature Encoding"},{"location":"02_real_data/fi_graph/#edge-direction-encoding","text":"Our network is set up as a directed network and edge directionality is intended to be primarily specified by this mechanism. For bi-directional edges ('-' or '<->'), two opposing edges are included in our network. For some more complex edge annotations and directions (e.g., multiple edge annotations or alternate-type bi-directionality), encoding edge direction may be a useful feature. To do this, we will create 2 features that can have the possible values [-1,0,1]. Edge directions can be though of as 3 element string: left_char , center_char , right_char center_char is always '-' and therefore unnecessary to encode left_char can be \"|\" (-1) or \"<\" (1) or neither (0), this will be the first feature right_char can be \"|\" (-1) or \">\" (1) or neither (0), this will be the second feature The edge direction strings used in reactome FI network. Direction | Count | feature --------------------------------------- - | 144182 | [0,0] <- | 40858 | [1,0] -> | 39438 | [0,1] <-> | 13177 | [1,1] |- | 5499 | [-1,0] -| | 4690 | [0,-1] |-> | 1454 | [-1,1] <-| | 1107 | [1,-1] |-| | 79 | [-1,-1]","title":"Edge Direction Encoding"},{"location":"02_real_data/fi_graph/#implementation","text":"The reactome FI network can be constructed by: edge_index, edge_attr, nodelist, annot_words = gnn_cdr.reactomefi.create_reactome_fi_graph()","title":"Implementation"},{"location":"02_real_data/fi_graph/#references","text":"Wu, G., Feng, X. & Stein, L. A human functional protein interaction network and its application to cancer data analysis. Genome Biol 11, R53 (2010). https://doi.org/10.1186/gb-2010-11-5-r53","title":"References"},{"location":"02_real_data/gene_dep/","text":"","title":"Gene Dependency"},{"location":"02_real_data/methylation/","text":"Methylation Data source and info Provided from CCLE 2019 release of CCLE DNA methylation data (promoter CpG clusters) . Citation: Mahmoud Ghandi, Franklin W. Huang, Judit Jan\u00e9-Valbuena, Gregory V. Kryukov, ... Todd R. Golub, Levi A. Garraway & William R. Sellers. 2019. Next-generation characterization of the Cancer Cell Line Encyclopedia. Nature 569, 503\u2013508 (2019). \"RRBS: For 843 cell lines, the RRBS method was used as previously described in [2]\" Boyle, P. et al. Gel-free multiplexed reduced representation bisulfite sequencing for large-scale DNA methylation profiling. Genome Biol. 13, R92 (2012). Reactome FI Coverage 11300 / 13609 (83%) of the reactome FI genes have methylation values. LINCS Coverage Of all the cell lines in LINCS, and within those lines that also have coverage in CNV , Expression and Mutation , there are 115 cell lines that also have methylation coverage. Methylation distribution Methylation values range from [0,1]. Cross-gene aggregation and mean-imputation The dataset provided by [1] (downloaded through DepMap) contains multiple CpG sites per Gene. We first convert to ensembl ID's (as some genes map to the same ensembl ID), and then aggregate the average methylation value for each ensembl gene identifier. After this step, ~1.5% of values were NA . NA values are imputed by filling with the mean methylation value (~0.35). Accessing individual cell line methylation We can get a specific cell line's methylation by using the method: x = gnn_cdr.depmap.get_cell_line_ccle_methyl(methyl, cell_line, genelist, impute_val) where: methyl is the pandas dataframe returned by load_ccle_methyl() . cell_line is the cell_iname identifier genelist is the list of genes to return; note, genes that are in genelist but not in expr will be imputed by impute_val . impute_val will be used to fill missing genes methylation value.","title":"Methylation"},{"location":"02_real_data/methylation/#methylation","text":"","title":"Methylation"},{"location":"02_real_data/methylation/#data-source-and-info","text":"Provided from CCLE 2019 release of CCLE DNA methylation data (promoter CpG clusters) . Citation: Mahmoud Ghandi, Franklin W. Huang, Judit Jan\u00e9-Valbuena, Gregory V. Kryukov, ... Todd R. Golub, Levi A. Garraway & William R. Sellers. 2019. Next-generation characterization of the Cancer Cell Line Encyclopedia. Nature 569, 503\u2013508 (2019). \"RRBS: For 843 cell lines, the RRBS method was used as previously described in [2]\" Boyle, P. et al. Gel-free multiplexed reduced representation bisulfite sequencing for large-scale DNA methylation profiling. Genome Biol. 13, R92 (2012).","title":"Data source and info"},{"location":"02_real_data/methylation/#reactome-fi-coverage","text":"11300 / 13609 (83%) of the reactome FI genes have methylation values.","title":"Reactome FI Coverage"},{"location":"02_real_data/methylation/#lincs-coverage","text":"Of all the cell lines in LINCS, and within those lines that also have coverage in CNV , Expression and Mutation , there are 115 cell lines that also have methylation coverage.","title":"LINCS Coverage"},{"location":"02_real_data/methylation/#methylation-distribution","text":"Methylation values range from [0,1].","title":"Methylation distribution"},{"location":"02_real_data/methylation/#cross-gene-aggregation-and-mean-imputation","text":"The dataset provided by [1] (downloaded through DepMap) contains multiple CpG sites per Gene. We first convert to ensembl ID's (as some genes map to the same ensembl ID), and then aggregate the average methylation value for each ensembl gene identifier. After this step, ~1.5% of values were NA . NA values are imputed by filling with the mean methylation value (~0.35).","title":"Cross-gene aggregation and mean-imputation"},{"location":"02_real_data/methylation/#accessing-individual-cell-line-methylation","text":"We can get a specific cell line's methylation by using the method: x = gnn_cdr.depmap.get_cell_line_ccle_methyl(methyl, cell_line, genelist, impute_val) where: methyl is the pandas dataframe returned by load_ccle_methyl() . cell_line is the cell_iname identifier genelist is the list of genes to return; note, genes that are in genelist but not in expr will be imputed by impute_val . impute_val will be used to fill missing genes methylation value.","title":"Accessing individual cell line methylation"},{"location":"02_real_data/mutation/","text":"Cancer Cell Line Encyclopedia Mutation Characterization DepMap Readme Genes:18784 Cell Lines:1759 Primary Diseases:35 Lineages:38 Source: Broad Institute DepMap Info Release README LINCS Coverage original # obs: 1269999 # obs lost converting to ensembl id: 62221 # of obs lost converting to cell_iname: 995092 final # obs: 212686 Of the total cell lines in LINCS (n=239), 138 of them have CCLE expression data including the same 133 that have CCLE expression data. Reactome FI Coverage After we map the 212,686 mutations (from above), to the covered Reactome FI gene nodes we have a 164,886 remaining mutations (78%). Encoding We will focus on two features of this dataset: Variant Annotation and Allelic Ratio (AC). Feature encoding: Allelic Ratio There are several options to use for allelic ratio, all specified with a _AC suffix. Due to missingness in the data, we will aggregate info from 3 sources (in order of confidence): CGA_WES_AC : the allelic ratio for this variant in all our WES/WGS(exon only) using a cell line adapted version of the 2019 CGA pipeline that includes germline filtering. RNAseq_AC : in Broad RNAseq data from the CCLE2 project (legacy) SangerWES_AC : in Sanger WES (called by sanger) (legacy) Our primary AC source (CGA_WES_AC) has ~22% missingness. All AC values are recorded as strings in the form ALTERNATE:REFERENCE , which we transform into a ratio using the function: \\[ AC_R = \\frac{ALTERNATE}{ALTERNATE + REFERENCE} \\] To ensure that these datatypes are concordant and interchangable, see the figure below for correlation of AC values. We then aggregate AC values using the logic: AC is equal to CGA_WES_AC if it's not Nan otherwise equal to RNAseq_AC if it's not Nan otherwise equal to SangerWES_AC if it's not Nan otherwise equal to mean of all CGA_WES_AC values (~0.5) Final AC distribution can be seen in the figure below. Feature Encoding: Variant Annotation Feature name: Variant_annotation There was no Depmap information available on this feature; however, I was able to find some insight from a biostars thread: [ A. Domingues ] \"Got the answer in the Forum of DepMap (closed access). I am pasting here the crucial part of the answer. If any one from DepMap has an issue with it, I am happy to remove it: We use Oncotator to annotate the mutations. The output of this tool is stored in the \u2018Variant_Classification\u2019 column of the mutation maf file The Variant_annotation column in the CCLE_mutations.csv MAF file We have added a Variant_annotation column in the DepMap mutation data, CCLE_mutations.csv 4, which groups mutations using more inclusive definitions. The Variant_annotation column labels a mutation as \u201cdamaging\u201d, \u201cother non-conserving\u201d, \u201cother conserving\u201d or \u201csilent\u201d using the Variant_Classification column and the definitions below.\" Oncotator information here . This feature has 4 categories as seen in the table below. Category count ------------------------------ other non-conserving 125327 silent 53541 damaging 33618 other conserving 200 Since the category other conserving has relatively few observations associated with it, we will merge it with other non-conserving and relabel them as other . The final 3 categroical labels will be: Category count ------------------------------ other 125527 silent 53541 damaging 33618 These labels will then be one-hot encoded . The final output for this datatype will be a 4 dimensional feature for each gene in our network, which will be zero if a given cell line does not have mutation in that gene, otherwise: mut_features = [other_bool, silent_bool, damaging_bool, AC] Where _bool indicates binary values. AC will be a float between 0-1. Variant Annotation vs Allelic Ratio To double check that we're not encoding redundant information, we checked the distribution of AC values for each variant annotation, see figure below. Implementation mut = gnn_cdr.depmap.load_ccle_mut() mut dataframe head: ensembl cell_iname variant AC -------------------------------------------------------- ENSG00000008128 HL60 other 0.237762 ENSG00000142611 HL60 other 0.531646 ENSG00000179163 HL60 other 0.454545 ENSG00000126705 HL60 other 0.512195 ENSG00000162526 HL60 silent 0.440860 To get an individual cell line's mutation features: obs = gnn_cdr.depmap.get_cell_line_ccle_mut(mut, cell_line='HL60', genelist=nodelist_fi, variant_encoding=['other', 'silent', 'damaging']) shape(obs) output: (13609, 4) References DepMap, Broad (2022): DepMap 22Q1 Public. figshare. Dataset. https://doi.org/10.6084/m9.figshare.19139906.v1 Mahmoud Ghandi, Franklin W. Huang, Judit Jan\u00e9-Valbuena, Gregory V. Kryukov, ... Todd R. Golub, Levi A. Garraway & William R. Sellers. 2019. Next-generation characterization of the Cancer Cell Line Encyclopedia. Nature 569, 503-508 (2019).","title":"Mutation"},{"location":"02_real_data/mutation/#cancer-cell-line-encyclopedia-mutation-characterization","text":"","title":"Cancer Cell Line Encyclopedia Mutation Characterization"},{"location":"02_real_data/mutation/#depmap-readme","text":"Genes:18784 Cell Lines:1759 Primary Diseases:35 Lineages:38 Source: Broad Institute DepMap Info Release README","title":"DepMap Readme"},{"location":"02_real_data/mutation/#lincs-coverage","text":"original # obs: 1269999 # obs lost converting to ensembl id: 62221 # of obs lost converting to cell_iname: 995092 final # obs: 212686 Of the total cell lines in LINCS (n=239), 138 of them have CCLE expression data including the same 133 that have CCLE expression data.","title":"LINCS Coverage"},{"location":"02_real_data/mutation/#reactome-fi-coverage","text":"After we map the 212,686 mutations (from above), to the covered Reactome FI gene nodes we have a 164,886 remaining mutations (78%).","title":"Reactome FI Coverage"},{"location":"02_real_data/mutation/#encoding","text":"We will focus on two features of this dataset: Variant Annotation and Allelic Ratio (AC).","title":"Encoding"},{"location":"02_real_data/mutation/#feature-encoding-allelic-ratio","text":"There are several options to use for allelic ratio, all specified with a _AC suffix. Due to missingness in the data, we will aggregate info from 3 sources (in order of confidence): CGA_WES_AC : the allelic ratio for this variant in all our WES/WGS(exon only) using a cell line adapted version of the 2019 CGA pipeline that includes germline filtering. RNAseq_AC : in Broad RNAseq data from the CCLE2 project (legacy) SangerWES_AC : in Sanger WES (called by sanger) (legacy) Our primary AC source (CGA_WES_AC) has ~22% missingness. All AC values are recorded as strings in the form ALTERNATE:REFERENCE , which we transform into a ratio using the function: \\[ AC_R = \\frac{ALTERNATE}{ALTERNATE + REFERENCE} \\] To ensure that these datatypes are concordant and interchangable, see the figure below for correlation of AC values. We then aggregate AC values using the logic: AC is equal to CGA_WES_AC if it's not Nan otherwise equal to RNAseq_AC if it's not Nan otherwise equal to SangerWES_AC if it's not Nan otherwise equal to mean of all CGA_WES_AC values (~0.5) Final AC distribution can be seen in the figure below.","title":"Feature encoding: Allelic Ratio"},{"location":"02_real_data/mutation/#feature-encoding-variant-annotation","text":"Feature name: Variant_annotation There was no Depmap information available on this feature; however, I was able to find some insight from a biostars thread: [ A. Domingues ] \"Got the answer in the Forum of DepMap (closed access). I am pasting here the crucial part of the answer. If any one from DepMap has an issue with it, I am happy to remove it: We use Oncotator to annotate the mutations. The output of this tool is stored in the \u2018Variant_Classification\u2019 column of the mutation maf file The Variant_annotation column in the CCLE_mutations.csv MAF file We have added a Variant_annotation column in the DepMap mutation data, CCLE_mutations.csv 4, which groups mutations using more inclusive definitions. The Variant_annotation column labels a mutation as \u201cdamaging\u201d, \u201cother non-conserving\u201d, \u201cother conserving\u201d or \u201csilent\u201d using the Variant_Classification column and the definitions below.\" Oncotator information here . This feature has 4 categories as seen in the table below. Category count ------------------------------ other non-conserving 125327 silent 53541 damaging 33618 other conserving 200 Since the category other conserving has relatively few observations associated with it, we will merge it with other non-conserving and relabel them as other . The final 3 categroical labels will be: Category count ------------------------------ other 125527 silent 53541 damaging 33618 These labels will then be one-hot encoded . The final output for this datatype will be a 4 dimensional feature for each gene in our network, which will be zero if a given cell line does not have mutation in that gene, otherwise: mut_features = [other_bool, silent_bool, damaging_bool, AC] Where _bool indicates binary values. AC will be a float between 0-1.","title":"Feature Encoding: Variant Annotation"},{"location":"02_real_data/mutation/#variant-annotation-vs-allelic-ratio","text":"To double check that we're not encoding redundant information, we checked the distribution of AC values for each variant annotation, see figure below.","title":"Variant Annotation vs Allelic Ratio"},{"location":"02_real_data/mutation/#implementation","text":"mut = gnn_cdr.depmap.load_ccle_mut() mut dataframe head: ensembl cell_iname variant AC -------------------------------------------------------- ENSG00000008128 HL60 other 0.237762 ENSG00000142611 HL60 other 0.531646 ENSG00000179163 HL60 other 0.454545 ENSG00000126705 HL60 other 0.512195 ENSG00000162526 HL60 silent 0.440860 To get an individual cell line's mutation features: obs = gnn_cdr.depmap.get_cell_line_ccle_mut(mut, cell_line='HL60', genelist=nodelist_fi, variant_encoding=['other', 'silent', 'damaging']) shape(obs) output: (13609, 4)","title":"Implementation"},{"location":"02_real_data/mutation/#references","text":"DepMap, Broad (2022): DepMap 22Q1 Public. figshare. Dataset. https://doi.org/10.6084/m9.figshare.19139906.v1 Mahmoud Ghandi, Franklin W. Huang, Judit Jan\u00e9-Valbuena, Gregory V. Kryukov, ... Todd R. Golub, Levi A. Garraway & William R. Sellers. 2019. Next-generation characterization of the Cancer Cell Line Encyclopedia. Nature 569, 503-508 (2019).","title":"References"},{"location":"02_real_data/overview/","text":"","title":"Overview"},{"location":"03_model/gnnCDR_arch/","text":"Graph Neural Network Cancer Drug Response (gnnCDR) This is our primary model, which incorporates protein-protein interactions as prior knowledge. We do this in a graph neural network (GNN) framework. The graph object is specified by edge_index (characterizes edges in the network) and edge_attr (characterizes edge features). Node features are specified by expr (t=0) for protein nodes and by drug for perturbation nodes. Similar to the naiveNN architecture, we predict a time-agnostic latent representation for each gene/node (specified as z in figure 1). This mechanism allows us to use a single, relatively simple, fully-connected neural network to be shared across all genes; This function takes the time-agnostic latent representation of a gene and time , and predicts a discrete time-point's expression value. In this way, we can train our model to predict time-series through individual time points. Graph structure Trainable Edge Attributes Edges are separated by edge type and can fall into one of the following categories: (agonist, targets, protein) (inhibitor, targets, protein) (KO, targets, protein) (KD, targets, protein) (OE, targets, protein) (protein, activates, protein) (protein, inhibits, protein) There are unique graph convolution parameter sets that operate on each edge type; however, we also desire to include trainable edge features in some of these edge types. Learning Binding Affinity To capture drug-target binding affinity , commonly characterized by the pharmacological binding affinity value, we add a trainable edge parameter for all edges of type: (agonist, targets, protein) (inhibitor, targets, protein) Learning context-specific PPIs Our approach relies on the premise that gene expression is largely mediated by PPIs. A pragmatic challenge of this premise is that most PPI databases are aggregations across multiple cell types and cancers \u2013 thus representing possible PPIs but unlikely to characterize any individual cellular context (e.g., only a subset of all possible PPIs are active in any given cell context). This means that our GNN must operate on an imperfect PPI graph that has few missing edges but many contextually false edges. We hypothesize that GNN flexibility will be able to account for the error in PPI data by taking advantage of other feature types ond mechanisms. We address this challenge in two ways. First, we include intrinsic cancer features (expression, mutation, copy number variation, methylation, or gene dependency) to mediate proper message passing between nodes. We hypothesize that our GNN model can use the local neighborhood of intrinsic features to mediate information flow along each edge. We rationalize that this assumption is valid in many cases. For instance, certain expression, methylation patterns, mutations or CNV patterns may indicate that a protein is not functional. Our model should use these node features to limit information flow along the respective incoming and outgoing edges. We note that our synthetic data does not model intrinsic features like mutation, CNV or methylation \u2013 and therefore, our preliminary synthetic evaluation of this approach is limited. Second, we use global features of cellular context to predict latent edge features. We use an attention mechanism to predict a protein-protein edge feature based on the cellular context, which allows our method to model complex cell specific edge behavior (e.g., for cell type A, we learn an importance feature for every PPI edge). We rationalize that intrinsic cancer features will not be able to account for more complex biological scenarios such as protein localization or quaternary structure, which are likely to cause distinct subsets of contextually active PPIs (rather than all in/out edges of a node being active/inactive). In our synthetic data, we one-hot encode cell-line (e.g., the unqiue synthetic data GRN model used to create each, so called \"cell line's\" unique behavior). This cell-line input is used to predict a set of edge features for every edge of type: (protein, activates, protein) (protein, inhibits, protein) As such, each cell-line can learn a unique set of PPI edge features. We believe that this mechanism will play an important role in capturing cell-type specific regulatory behavior. Example dummy_data = train_dataset.__getitem__(0) # HeteroData object from SynthHeteroDataset gene_names = train_dataset.gene_names # gene names, specifies node index pert_names = train_dataset.pert_names # perturbation names pert_map = train_dataset.pert_map # perturbation map, specifies each perturbation type name's and node index (6 pert. types) hidden_channels = 25 # the number of hidden channels to use in each GNN layer / convolution num_layers = 10 # the number of GNN layers to include nheads = 5 # the number of attention heads to use in PPI convolutions beta = 0.8 # parameter specifying residual connection strength dropout = 0.3 # regularization parameter pairnorm = True # whether to use `pairnorm` or not - improves performance when `num_layers` > 3 ######################################################################## ######################################################################## model = gnn_cdr.model.GNNCDR( gene_names = gene_names, pert_names = pert_names, pert_map = pert_map, data = dummy_data, hidden_channels = hidden_channels, num_layers = num_layers, nheads = nheads, beta = beta, dropout = dropout, pairnorm = pairnorm )","title":"gnnCDR"},{"location":"03_model/gnnCDR_arch/#graph-neural-network-cancer-drug-response-gnncdr","text":"This is our primary model, which incorporates protein-protein interactions as prior knowledge. We do this in a graph neural network (GNN) framework. The graph object is specified by edge_index (characterizes edges in the network) and edge_attr (characterizes edge features). Node features are specified by expr (t=0) for protein nodes and by drug for perturbation nodes. Similar to the naiveNN architecture, we predict a time-agnostic latent representation for each gene/node (specified as z in figure 1). This mechanism allows us to use a single, relatively simple, fully-connected neural network to be shared across all genes; This function takes the time-agnostic latent representation of a gene and time , and predicts a discrete time-point's expression value. In this way, we can train our model to predict time-series through individual time points.","title":"Graph Neural Network Cancer Drug Response (gnnCDR)"},{"location":"03_model/gnnCDR_arch/#graph-structure","text":"","title":"Graph structure"},{"location":"03_model/gnnCDR_arch/#trainable-edge-attributes","text":"Edges are separated by edge type and can fall into one of the following categories: (agonist, targets, protein) (inhibitor, targets, protein) (KO, targets, protein) (KD, targets, protein) (OE, targets, protein) (protein, activates, protein) (protein, inhibits, protein) There are unique graph convolution parameter sets that operate on each edge type; however, we also desire to include trainable edge features in some of these edge types.","title":"Trainable Edge Attributes"},{"location":"03_model/gnnCDR_arch/#learning-binding-affinity","text":"To capture drug-target binding affinity , commonly characterized by the pharmacological binding affinity value, we add a trainable edge parameter for all edges of type: (agonist, targets, protein) (inhibitor, targets, protein)","title":"Learning Binding Affinity"},{"location":"03_model/gnnCDR_arch/#learning-context-specific-ppis","text":"Our approach relies on the premise that gene expression is largely mediated by PPIs. A pragmatic challenge of this premise is that most PPI databases are aggregations across multiple cell types and cancers \u2013 thus representing possible PPIs but unlikely to characterize any individual cellular context (e.g., only a subset of all possible PPIs are active in any given cell context). This means that our GNN must operate on an imperfect PPI graph that has few missing edges but many contextually false edges. We hypothesize that GNN flexibility will be able to account for the error in PPI data by taking advantage of other feature types ond mechanisms. We address this challenge in two ways. First, we include intrinsic cancer features (expression, mutation, copy number variation, methylation, or gene dependency) to mediate proper message passing between nodes. We hypothesize that our GNN model can use the local neighborhood of intrinsic features to mediate information flow along each edge. We rationalize that this assumption is valid in many cases. For instance, certain expression, methylation patterns, mutations or CNV patterns may indicate that a protein is not functional. Our model should use these node features to limit information flow along the respective incoming and outgoing edges. We note that our synthetic data does not model intrinsic features like mutation, CNV or methylation \u2013 and therefore, our preliminary synthetic evaluation of this approach is limited. Second, we use global features of cellular context to predict latent edge features. We use an attention mechanism to predict a protein-protein edge feature based on the cellular context, which allows our method to model complex cell specific edge behavior (e.g., for cell type A, we learn an importance feature for every PPI edge). We rationalize that intrinsic cancer features will not be able to account for more complex biological scenarios such as protein localization or quaternary structure, which are likely to cause distinct subsets of contextually active PPIs (rather than all in/out edges of a node being active/inactive). In our synthetic data, we one-hot encode cell-line (e.g., the unqiue synthetic data GRN model used to create each, so called \"cell line's\" unique behavior). This cell-line input is used to predict a set of edge features for every edge of type: (protein, activates, protein) (protein, inhibits, protein) As such, each cell-line can learn a unique set of PPI edge features. We believe that this mechanism will play an important role in capturing cell-type specific regulatory behavior.","title":"Learning context-specific PPIs"},{"location":"03_model/gnnCDR_arch/#example","text":"dummy_data = train_dataset.__getitem__(0) # HeteroData object from SynthHeteroDataset gene_names = train_dataset.gene_names # gene names, specifies node index pert_names = train_dataset.pert_names # perturbation names pert_map = train_dataset.pert_map # perturbation map, specifies each perturbation type name's and node index (6 pert. types) hidden_channels = 25 # the number of hidden channels to use in each GNN layer / convolution num_layers = 10 # the number of GNN layers to include nheads = 5 # the number of attention heads to use in PPI convolutions beta = 0.8 # parameter specifying residual connection strength dropout = 0.3 # regularization parameter pairnorm = True # whether to use `pairnorm` or not - improves performance when `num_layers` > 3 ######################################################################## ######################################################################## model = gnn_cdr.model.GNNCDR( gene_names = gene_names, pert_names = pert_names, pert_map = pert_map, data = dummy_data, hidden_channels = hidden_channels, num_layers = num_layers, nheads = nheads, beta = beta, dropout = dropout, pairnorm = pairnorm )","title":"Example"},{"location":"03_model/naiveNN_arch/","text":"Naive Neural Network (naiveNN) This represents the baseline model; which has no way of including prior knowledge of protein-protein interactions (PPIs). For the most part, this can be conceptualized as a simple feed forward neural network; however, we do employ a similar tactic to gnnCDR of fist predicting a time-agnostic latent representation for each gene and then using a shared set of parameters to predict a time series. The expr (t=0) input represents the gene expression abundance at baseline (no drug), and is the expression value at time=0 in each expression time series. The drug input identifies the presence of a given perturbation - chemical perturbations are active when they have non-zero values, and which represent drug concentration. Genetic perturbations are specified as active with an arbitrary value of 1. A feed forward fully connected neural network then predicts a latent representation z for every gene. This is intended to represent a time-agonistic representation of that genes expression time series, e.g., response to the perturbagen. The time-agnostic latent vector of each gene is then treated as input along with a specific time point ( time in the figure) to a second neural network, which predicts a discrete expression value for every gene. In this way, our model shares the time-series function across all genes. This was found to be a significant improvement over a classical neural network (e.g., no time-agnostic latent prediction or shared time-series function). For convenience, we've added the data structures: data.baseline data.x data.y data.time To the SynthHeteroDataset HeteroData object, which provides the relevant data in (observation, feature) views. Example To initialize a model: data = train_dataset.__getitem__(0) # HeteroData object from SynthHeteroDataset in_channels = data['protein'].num_nodes + data.pert_all.size(1) # input channels to neural network (not including time) out_channels = data['protein'].num_nodes # number of genes dropout = 0.15 # regularization parameter num_layers = 2 # number of fully connected layers hidden_channels = 100 # number of hidden units in each layer model = gnn_cdr.model.NaiveNN(in_channels=in_channels, out_channels=out_channels, hidden_channels=hidden_channels, num_layers=num_layers, dropout=dropout)","title":"naiveNN"},{"location":"03_model/naiveNN_arch/#naive-neural-network-naivenn","text":"This represents the baseline model; which has no way of including prior knowledge of protein-protein interactions (PPIs). For the most part, this can be conceptualized as a simple feed forward neural network; however, we do employ a similar tactic to gnnCDR of fist predicting a time-agnostic latent representation for each gene and then using a shared set of parameters to predict a time series. The expr (t=0) input represents the gene expression abundance at baseline (no drug), and is the expression value at time=0 in each expression time series. The drug input identifies the presence of a given perturbation - chemical perturbations are active when they have non-zero values, and which represent drug concentration. Genetic perturbations are specified as active with an arbitrary value of 1. A feed forward fully connected neural network then predicts a latent representation z for every gene. This is intended to represent a time-agonistic representation of that genes expression time series, e.g., response to the perturbagen. The time-agnostic latent vector of each gene is then treated as input along with a specific time point ( time in the figure) to a second neural network, which predicts a discrete expression value for every gene. In this way, our model shares the time-series function across all genes. This was found to be a significant improvement over a classical neural network (e.g., no time-agnostic latent prediction or shared time-series function). For convenience, we've added the data structures: data.baseline data.x data.y data.time To the SynthHeteroDataset HeteroData object, which provides the relevant data in (observation, feature) views.","title":"Naive Neural Network (naiveNN)"},{"location":"03_model/naiveNN_arch/#example","text":"To initialize a model: data = train_dataset.__getitem__(0) # HeteroData object from SynthHeteroDataset in_channels = data['protein'].num_nodes + data.pert_all.size(1) # input channels to neural network (not including time) out_channels = data['protein'].num_nodes # number of genes dropout = 0.15 # regularization parameter num_layers = 2 # number of fully connected layers hidden_channels = 100 # number of hidden units in each layer model = gnn_cdr.model.NaiveNN(in_channels=in_channels, out_channels=out_channels, hidden_channels=hidden_channels, num_layers=num_layers, dropout=dropout)","title":"Example"},{"location":"03_model/ppi_context_edge_weight_decay/","text":"Contextual protein-protein trainable edge weights As we've mentioned previously, we recognize that using a shared gene-regulatory network (GRN) or protein-protein interaction (PPI) graph will result in contextually false edges. This is due to the fact that no individual cell type participates in all PPIs. Rather, each celltype has a unique set of PPIs (and likely GRN); However, we are limited in that we do not know cell-type specific GRNs or PPI graphs and therefore have introduced contextual protein-protein trainable edge weights . In practice, this is implemented by a linear layer (weight + bias) such that our context features (In synthetic data, this is a one-hot encoded vector specifying the cell model (e.g., \"cell line\" analog)) selects a unique set of edge weights. ~~We then pass the edge weights into a sigmoid function to scale the edge features between 0,1.~~ Our expectation is that our model will be able to learn which edges do not exist (or differences in edge flux), and thereby significantly improve performance and predict cell line differences in drug response. We rationalize that including the bias term in this mechanism will allow the model to distinguish edges that do not exist for all cell lines (a.k.a., true false edges). Figure 1 : Simple depiction of how two cell lines or cell types (X,Y) can have a unique set of edge weights, which we expect to allow for cell type specific drug response. However, one potential challenge to this approach is overfitting due to high model complexity. As our PPI network grows, so does the number of trainable edge weights we must include and this makes up a significant proportion of the model's overall trainable edge weights. The number of PPI trainable edge weights (n) scale as: \\[ n = F*E*(C + 1) \\] Where \\(F\\) is the number of features per edge, \\(E\\) is the number of edges, and \\(C\\) is the number of cell lines in the model. A practical example: when initializing a model to predict outputs on the Ecoli GRN (1556 nodes) synthetic data, with 10 \"cell line\" models and 1 feature per PPI edge, there are 88,352 PPI edge features and this makes up ~95% of the total model parameters. One assumption we've made for this problem is that the majority of PPI edges are shared across all cell-lines/cell-types and that perhaps 5-10% of the edges differ. As such, we expect useful PPI edge features to be sparse. We considered using an approximate bayesian method, such as variational autoencoder or categorical variables such as the softmax-gumbel method, which would allow us to specify priors on the sparsity of our features; however, for simplicity we opted to use a strong L2 penalty on the PPI contextual edge features. This PPI penalty can be specified using the edge_wd parameter in the settings.ini file and the PPI edges L2 norm can be retrieved using gnn_cdr.model.GNNCDR.get_ppi_edge_l2() .","title":"PPI trainable edge weights"},{"location":"03_model/ppi_context_edge_weight_decay/#contextual-protein-protein-trainable-edge-weights","text":"As we've mentioned previously, we recognize that using a shared gene-regulatory network (GRN) or protein-protein interaction (PPI) graph will result in contextually false edges. This is due to the fact that no individual cell type participates in all PPIs. Rather, each celltype has a unique set of PPIs (and likely GRN); However, we are limited in that we do not know cell-type specific GRNs or PPI graphs and therefore have introduced contextual protein-protein trainable edge weights . In practice, this is implemented by a linear layer (weight + bias) such that our context features (In synthetic data, this is a one-hot encoded vector specifying the cell model (e.g., \"cell line\" analog)) selects a unique set of edge weights. ~~We then pass the edge weights into a sigmoid function to scale the edge features between 0,1.~~ Our expectation is that our model will be able to learn which edges do not exist (or differences in edge flux), and thereby significantly improve performance and predict cell line differences in drug response. We rationalize that including the bias term in this mechanism will allow the model to distinguish edges that do not exist for all cell lines (a.k.a., true false edges). Figure 1 : Simple depiction of how two cell lines or cell types (X,Y) can have a unique set of edge weights, which we expect to allow for cell type specific drug response. However, one potential challenge to this approach is overfitting due to high model complexity. As our PPI network grows, so does the number of trainable edge weights we must include and this makes up a significant proportion of the model's overall trainable edge weights. The number of PPI trainable edge weights (n) scale as: \\[ n = F*E*(C + 1) \\] Where \\(F\\) is the number of features per edge, \\(E\\) is the number of edges, and \\(C\\) is the number of cell lines in the model. A practical example: when initializing a model to predict outputs on the Ecoli GRN (1556 nodes) synthetic data, with 10 \"cell line\" models and 1 feature per PPI edge, there are 88,352 PPI edge features and this makes up ~95% of the total model parameters. One assumption we've made for this problem is that the majority of PPI edges are shared across all cell-lines/cell-types and that perhaps 5-10% of the edges differ. As such, we expect useful PPI edge features to be sparse. We considered using an approximate bayesian method, such as variational autoencoder or categorical variables such as the softmax-gumbel method, which would allow us to specify priors on the sparsity of our features; however, for simplicity we opted to use a strong L2 penalty on the PPI contextual edge features. This PPI penalty can be specified using the edge_wd parameter in the settings.ini file and the PPI edges L2 norm can be retrieved using gnn_cdr.model.GNNCDR.get_ppi_edge_l2() .","title":"Contextual protein-protein trainable edge weights"},{"location":"03_model/targets_and_metrics/","text":"The Choice of Target (Endogenous feature) We have two options for our choice of endogenous feature: 1. Absolute `perturbed expression` 2. Change in `perturbed expression` Assuming we have an accurate baseline (e.g., unperturbed-expression) we should be able to convert between either endogenous variable. Arguably, absolute pertubed expression is more convenient and useful; however, there are two challenges with predicting absolute perturbed expression . 1. The distribution of targets are not centered or scaled, which could induce training issues (See figure 1). 2. In any given observation, the grand majority of genes do not have significant change in expression. As such, the baseline (unperturbed) expression predicts the endogenous variable very well, and we call this the `naive` prediction - which we often use as a baseline. **When we use the Ecoli gene regulatory network (GRN) to produce synthetic data (1556 genes), our `naive` multi-output values are: uniform weighted R2: ~0.95 variance weighted R2: ~0.99 (R2 score between absolute perturbed expression and x is `absolute unperturbed expression) The interpretation of this is that almost all the variance is explained by cell to cell variance, rather than by perturbed expression changes. There are a number of factors that contribute to this behavior in our synthetic data: 1. A lack of noise (optional) 2. Observations can range from time=0 (e.g., baseline) to time=500 3. Genetic perturbations only have a single gene target - therefore downstream changes may be minimal 4. Chemical perturbations have a range of concentrations - small concentrations may create a minimal change in expression. Figure 1: A random subset of the Synthetic data generated from the full Ecoli gene regulatory network with 1556 gene nodes. No noise was added to this synthetic data. (left) The absolute value of perturbed expression. Note that the data is between 0,2 and the y-axis is log scaled. Normally, GeneNetWeaver produces data between 0-1; however, our method of simulating chemical perturbations occasionally produces values greater than 1. (right) The change in expression as calcuated by absolute perturbed expression - absolute unperturbed expression . Figure 2 : A random subset of the Synthetic data generated from the full Ecoli gene regulatory network with 1556 gene nodes. No noise was added to this synthetic data. Here we have plotted the absolute perturbed expression (red) and the change in expression . Note that the change in perturbed expression is almost always zero. **For these reasons, we have chosen to use the change in pertubed expression as our endogenous variable.","title":"Choice of Target and Metrics"},{"location":"03_model/targets_and_metrics/#the-choice-of-target-endogenous-feature","text":"We have two options for our choice of endogenous feature: 1. Absolute `perturbed expression` 2. Change in `perturbed expression` Assuming we have an accurate baseline (e.g., unperturbed-expression) we should be able to convert between either endogenous variable. Arguably, absolute pertubed expression is more convenient and useful; however, there are two challenges with predicting absolute perturbed expression . 1. The distribution of targets are not centered or scaled, which could induce training issues (See figure 1). 2. In any given observation, the grand majority of genes do not have significant change in expression. As such, the baseline (unperturbed) expression predicts the endogenous variable very well, and we call this the `naive` prediction - which we often use as a baseline. **When we use the Ecoli gene regulatory network (GRN) to produce synthetic data (1556 genes), our `naive` multi-output values are: uniform weighted R2: ~0.95 variance weighted R2: ~0.99 (R2 score between absolute perturbed expression and x is `absolute unperturbed expression) The interpretation of this is that almost all the variance is explained by cell to cell variance, rather than by perturbed expression changes. There are a number of factors that contribute to this behavior in our synthetic data: 1. A lack of noise (optional) 2. Observations can range from time=0 (e.g., baseline) to time=500 3. Genetic perturbations only have a single gene target - therefore downstream changes may be minimal 4. Chemical perturbations have a range of concentrations - small concentrations may create a minimal change in expression. Figure 1: A random subset of the Synthetic data generated from the full Ecoli gene regulatory network with 1556 gene nodes. No noise was added to this synthetic data. (left) The absolute value of perturbed expression. Note that the data is between 0,2 and the y-axis is log scaled. Normally, GeneNetWeaver produces data between 0-1; however, our method of simulating chemical perturbations occasionally produces values greater than 1. (right) The change in expression as calcuated by absolute perturbed expression - absolute unperturbed expression . Figure 2 : A random subset of the Synthetic data generated from the full Ecoli gene regulatory network with 1556 gene nodes. No noise was added to this synthetic data. Here we have plotted the absolute perturbed expression (red) and the change in expression . Note that the change in perturbed expression is almost always zero. **For these reasons, we have chosen to use the change in pertubed expression as our endogenous variable.","title":"The Choice of Target (Endogenous feature)"},{"location":"pages_usage/mkdocs_guides/","text":"Links to mkdocs guides Material General Toc Material Color Palette","title":"Mkdocs Help"},{"location":"pages_usage/mkdocs_guides/#links-to-mkdocs-guides","text":"","title":"Links to mkdocs guides"},{"location":"pages_usage/mkdocs_guides/#material","text":"General Toc Material Color Palette","title":"Material"},{"location":"pages_usage/syntax_examples/","text":"List of random syntax examples Downloading Data download_abcd_batch.sh - Script to call NDA downloader download.py - NDA downloader (Fair Lab) . File Path Func ./ download_abcd_batch.sh docs Script to call NDA downloader ../../ download.py docs NDA data downloader Name Required Details Python Markdown Yes Python Markdown must be installed as it is the Markdown parser that is being used. Pygments (optional) No If Pygments Syntax highlighting is desired, Pygments must be installed. This can be omitted, and code blocks will be formatted for use with JavaScript code highlighters. Autoembed table from csv ??? note \"Dynamically embedding a table from a .csv\" === \"Adding a new table\" This is syntax to ad a new table === \"Syntax\" | col1 | col2 | col3 | col4 | col5 | col6 | col7 | |-------:|-------:|-------:|-------:|-------:|-------:|-------:| | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | 7 | 8 | 9 | 10 | 11 | 12 | 13 | === \"output\" | col1 | col2 | col3 | col4 | col5 | col6 | col7 | |-------:|-------:|-------:|-------:|-------:|-------:|-------:| | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | 7 | 8 | 9 | 10 | 11 | 12 | 13 | ### Add entire script --8<-- \"file1.ext\" \"file2.ext\" --8<-- Code snippets add line numer and highlight lines 2 and language linenums=\"1\" hl_lines=\"2 3\" ??? bug pycon3 linenums=\"1\" hl_lines=\"2 3\" >>> import markdown >>> text = \"A link https://google.com\" >>> html = markdown.markdown(text, extensions=['pymdownx.magiclink']) ??? note === \"Output\" Task List - [X] item 1 * [X] item A * [ ] item B more text + [x] item a + [ ] item b + [x] item c * [X] item C - [ ] item 2 - [ ] item 3 === \"Markdown\" ``` Task List - [X] item 1 * [X] item A * [ ] item B more text + [x] item a + [ ] item b + [x] item c * [X] item C - [ ] item 2 - [ ] item 3 ``` !!! note test test for note !!! todo test test for note !!! tldr test test for note !!! important test test for note !!! done test test for note !!! faq test test for note !!! attention test test for note !!! error test test for note !!! bug test test for note !!! quote test test for note !!! reminder I still need to download the data ???+ failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ??? example \"Inline Highlighted Code Example\" === \"Output\" Here is some code: `#!py3 import pymdownx; pymdownx.__version__` The mock shebang will be treated like text here: ` #!js var test = 0; `. === \"Markdown\" ``` Here is some code: `#!py3 import pymdownx; pymdownx.__version__`. The mock shebang will be treated like text here: ` #!js var test = 0; `. ``` The mock shebang will be treated like text here: #!js var test = 0; . srun $PYTHON_ENV download.py \\ -i $manifest \\ -o $outdir \\ -s $sublist \\ -l $logfiles \\ -d $subset -p 6 import pandas as pd import numpy as np def test_func(var1, var2): return x Clinical Data data_subsets.txt - List of derivatives subject_list.txt - List of subjects","title":"Mkdocs Syntax"},{"location":"pages_usage/syntax_examples/#list-of-random-syntax-examples","text":"","title":"List of random syntax examples"},{"location":"pages_usage/syntax_examples/#downloading-data","text":"download_abcd_batch.sh - Script to call NDA downloader download.py - NDA downloader (Fair Lab) . File Path Func ./ download_abcd_batch.sh docs Script to call NDA downloader ../../ download.py docs NDA data downloader Name Required Details Python Markdown Yes Python Markdown must be installed as it is the Markdown parser that is being used. Pygments (optional) No If Pygments Syntax highlighting is desired, Pygments must be installed. This can be omitted, and code blocks will be formatted for use with JavaScript code highlighters.","title":"Downloading Data"},{"location":"pages_usage/syntax_examples/#autoembed-table-from-csv","text":"??? note \"Dynamically embedding a table from a .csv\" === \"Adding a new table\" This is syntax to ad a new table === \"Syntax\" | col1 | col2 | col3 | col4 | col5 | col6 | col7 | |-------:|-------:|-------:|-------:|-------:|-------:|-------:| | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | 7 | 8 | 9 | 10 | 11 | 12 | 13 | === \"output\" | col1 | col2 | col3 | col4 | col5 | col6 | col7 | |-------:|-------:|-------:|-------:|-------:|-------:|-------:| | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | 7 | 8 | 9 | 10 | 11 | 12 | 13 | ### Add entire script --8<-- \"file1.ext\" \"file2.ext\" --8<--","title":"Autoembed table from csv"},{"location":"pages_usage/syntax_examples/#code-snippets","text":"add line numer and highlight lines 2 and language linenums=\"1\" hl_lines=\"2 3\" ??? bug pycon3 linenums=\"1\" hl_lines=\"2 3\" >>> import markdown >>> text = \"A link https://google.com\" >>> html = markdown.markdown(text, extensions=['pymdownx.magiclink']) ??? note === \"Output\" Task List - [X] item 1 * [X] item A * [ ] item B more text + [x] item a + [ ] item b + [x] item c * [X] item C - [ ] item 2 - [ ] item 3 === \"Markdown\" ``` Task List - [X] item 1 * [X] item A * [ ] item B more text + [x] item a + [ ] item b + [x] item c * [X] item C - [ ] item 2 - [ ] item 3 ``` !!! note test test for note !!! todo test test for note !!! tldr test test for note !!! important test test for note !!! done test test for note !!! faq test test for note !!! attention test test for note !!! error test test for note !!! bug test test for note !!! quote test test for note !!! reminder I still need to download the data ???+ failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ??? example \"Inline Highlighted Code Example\" === \"Output\" Here is some code: `#!py3 import pymdownx; pymdownx.__version__` The mock shebang will be treated like text here: ` #!js var test = 0; `. === \"Markdown\" ``` Here is some code: `#!py3 import pymdownx; pymdownx.__version__`. The mock shebang will be treated like text here: ` #!js var test = 0; `. ``` The mock shebang will be treated like text here: #!js var test = 0; . srun $PYTHON_ENV download.py \\ -i $manifest \\ -o $outdir \\ -s $sublist \\ -l $logfiles \\ -d $subset -p 6 import pandas as pd import numpy as np def test_func(var1, var2): return x","title":"Code snippets"},{"location":"pages_usage/syntax_examples/#clinical-data","text":"data_subsets.txt - List of derivatives subject_list.txt - List of subjects","title":"Clinical Data"}]}